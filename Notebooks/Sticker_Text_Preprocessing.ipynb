{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-13T13:48:50.404735Z",
     "start_time": "2025-02-13T13:48:44.406052Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:49:08.159030Z",
     "start_time": "2025-02-13T13:49:08.135812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "id": "e5b5b3d459d9c4e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mac GPU (MPS)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:51:23.825842Z",
     "start_time": "2025-02-13T13:51:23.743046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reading the dataset\n",
    "alexator_df = pd.read_csv('../data/Alexator/alexator_stickers_desc.csv')\n",
    "flaticon_df = pd.read_csv('../data/flaticon/flaticon_stickers_desc.csv')\n",
    "freepik_df = pd.read_csv('../data/freepik/freepik_stickers_desc.csv')"
   ],
   "id": "3243e2d8217b127c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:52:37.583390Z",
     "start_time": "2025-02-13T13:52:37.573251Z"
    }
   },
   "cell_type": "code",
   "source": "alexator_df.info()",
   "id": "eaca7f30e6a351c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     4331 non-null   object\n",
      " 1   description  4331 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.8+ KB\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:52:58.660275Z",
     "start_time": "2025-02-13T13:52:58.651755Z"
    }
   },
   "cell_type": "code",
   "source": "flaticon_df.info()",
   "id": "eaa42cff99080a21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30402 entries, 0 to 30401\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   image        30402 non-null  object\n",
      " 1   title        30402 non-null  object\n",
      " 2   tags         30402 non-null  object\n",
      " 3   filename     30402 non-null  object\n",
      " 4   description  30402 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:53:01.403453Z",
     "start_time": "2025-02-13T13:53:01.393666Z"
    }
   },
   "cell_type": "code",
   "source": "freepik_df.info()",
   "id": "212569a49f67fe6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9844 entries, 0 to 9843\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        0 non-null      float64\n",
      " 1   tags         9814 non-null   object \n",
      " 2   image        9844 non-null   object \n",
      " 3   filename     9844 non-null   object \n",
      " 4   description  9844 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 384.7+ KB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:53:16.484240Z",
     "start_time": "2025-02-13T13:53:16.471252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate the DataFrames row-wise\n",
    "merged_df = pd.concat([alexator_df, flaticon_df, freepik_df], ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "merged_df.info()"
   ],
   "id": "eacf52d9582f0f7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44577 entries, 0 to 44576\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     44577 non-null  object\n",
      " 1   description  44577 non-null  object\n",
      " 2   image        40246 non-null  object\n",
      " 3   title        30402 non-null  object\n",
      " 4   tags         40216 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Handling duplicates in description and tags combination\n",
   "id": "720bf77b66e3e2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:54:01.360600Z",
     "start_time": "2025-02-13T13:54:01.285422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replace duplicate descriptions with Null (Because most of them don't make sense and are incorrect)\n",
    "duplicate_descriptions = merged_df['description'].duplicated(keep=False)\n",
    "merged_df.loc[duplicate_descriptions, 'description'] = None\n",
    "\n",
    "\"\"\"Some generated descriptions have errors such as \"a big boy boy boy boy boy....\"\n",
    "So, we want to remove such descriptions that have incorrect descriptions\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Reference: ChatGPT-4o\n",
    "Prompt:  I need to check for a certain type of error and remove those rows in my dataframe. The error is that in some description, certain words are repeated multiple time consecutively. Example: \"happy man with two polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar\"\n",
    "\"\"\"\n",
    "# Replace descriptions with repeated words with Null\n",
    "def has_repeated_words(text):\n",
    "    if not text or pd.isna(text):  # Skip null or empty strings\n",
    "        return False\n",
    "    \n",
    "    # Regex to find words repeated consecutively at least 3 times (case insensitive)\n",
    "    pattern = r'\\b(\\w+)(?:\\s+\\1){2,}\\b'\n",
    "    return bool(re.search(pattern, text, re.IGNORECASE))\n",
    "\n",
    "merged_df.loc[merged_df['description'].apply(has_repeated_words), 'description'] = None\n",
    "\n",
    "# Remove rows with exact same tags AND description, keeping the first occurrence (We don't want different immages with same details)\n",
    "cleaned_df = merged_df.drop_duplicates(subset=['tags', 'description'], keep='first')\n",
    "\n",
    "# Check the new number of rows\n",
    "print(f\"Number of rows after removing rows with exact same tags and descriptions: {cleaned_df.shape[0]}\")"
   ],
   "id": "aaa3105afa9166ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing rows with exact same tags and descriptions: 38807\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:55:06.942513Z",
     "start_time": "2025-02-13T13:55:06.933085Z"
    }
   },
   "cell_type": "code",
   "source": "cleaned_df.info()",
   "id": "d97176fdcec6e41a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38807 entries, 0 to 44576\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     38807 non-null  object\n",
      " 1   description  26858 non-null  object\n",
      " 2   image        35101 non-null  object\n",
      " 3   title        27135 non-null  object\n",
      " 4   tags         35091 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Handling Tags and Descriptions",
   "id": "1dab23f567f3cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:55:43.477067Z",
     "start_time": "2025-02-13T13:55:43.473276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_duplicates(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = sorted(set(word.strip() for word in text.split(\",\")))\n",
    "    return ', '.join(unique_words)  # Join back into a string"
   ],
   "id": "79e0e24323ced210",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:55:47.912270Z",
     "start_time": "2025-02-13T13:55:47.813904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove duplicates\n",
    "final_df = cleaned_df.copy()\n",
    "final_df[\"tags\"] = final_df[\"tags\"].progress_apply(remove_duplicates)"
   ],
   "id": "ab567bbf0bba6630",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38807/38807 [00:00<00:00, 502343.56it/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "### Need to conduct spelling correction in description column here as well",
   "id": "621316ad705b04a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embedding using Sentence BERT",
   "id": "3fe49ea25a063e30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "730ea9d04cda84e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
