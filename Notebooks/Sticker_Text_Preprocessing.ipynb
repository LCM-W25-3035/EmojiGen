{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.843205Z",
     "start_time": "2025-04-05T00:23:43.840671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from spellchecker import SpellChecker\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5b5b3d459d9c4e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.944195Z",
     "start_time": "2025-04-05T00:23:43.941153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c68bfba918eb917c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.952781Z",
     "start_time": "2025-04-05T00:23:43.950855Z"
    }
   },
   "outputs": [],
   "source": [
    "# spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3243e2d8217b127c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.960674Z",
     "start_time": "2025-04-05T00:23:43.954318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "alexator_df = pd.read_csv('../data/alexator_stickers_desc.csv')\n",
    "# flaticon_df = pd.read_csv('../data/flaticon_stickers_desc.csv')\n",
    "# freepik_df = pd.read_csv('../data/freepik_stickers_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eaca7f30e6a351c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.969661Z",
     "start_time": "2025-04-05T00:23:43.966307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     4331 non-null   object\n",
      " 1   description  4331 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.8+ KB\n"
     ]
    }
   ],
   "source": [
    "alexator_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaa42cff99080a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.983014Z",
     "start_time": "2025-04-05T00:23:43.981243Z"
    }
   },
   "outputs": [],
   "source": [
    "# flaticon_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "212569a49f67fe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:43.996161Z",
     "start_time": "2025-04-05T00:23:43.994208Z"
    }
   },
   "outputs": [],
   "source": [
    "# freepik_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eacf52d9582f0f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.008572Z",
     "start_time": "2025-04-05T00:23:44.004453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     4331 non-null   object\n",
      " 1   description  4331 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames row-wise\n",
    "# merged_df = pd.concat([alexator_df, flaticon_df, freepik_df], ignore_index=True)\n",
    "merged_df = alexator_df\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bf77b66e3e2e1",
   "metadata": {},
   "source": [
    "## Handling duplicates in description and tags combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aaa3105afa9166ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.021374Z",
     "start_time": "2025-04-05T00:23:44.018939Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Replace duplicate descriptions with Null (Because most of them don't make sense and are incorrect)\n",
    "# duplicate_descriptions = merged_df['description'].duplicated(keep=False)\n",
    "# merged_df.loc[duplicate_descriptions, 'description'] = None\n",
    "# \n",
    "# \"\"\"Some generated descriptions have errors such as \"a big boy boy boy boy boy....\"\n",
    "# So, we want to remove such descriptions that have incorrect descriptions\n",
    "# \"\"\"\n",
    "# \n",
    "# \"\"\"\n",
    "# Reference: ChatGPT-4o\n",
    "# Prompt: I need to check for a certain type of error and remove those rows in my dataframe. The error is that in some description, certain words are repeated multiple time consecutively. Example: \"happy man with two polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar polar\"\n",
    "# \"\"\"\n",
    "# # Replace descriptions with repeated words with Null\n",
    "# def has_repeated_words(text):\n",
    "#     if not text or pd.isna(text):  # Skip null or empty strings\n",
    "#         return False\n",
    "#     \n",
    "#     # Regex to find words repeated consecutively at least 3 times (case insensitive)\n",
    "#     pattern = r'\\b(\\w+)(?:\\s+\\1){2,}\\b'\n",
    "#     return bool(re.search(pattern, text, re.IGNORECASE))\n",
    "# \n",
    "# merged_df.loc[merged_df['description'].apply(has_repeated_words), 'description'] = None\n",
    "# \n",
    "# # Remove rows with exact same tags AND description, keeping the first occurrence (We don't want different immages with same details)\n",
    "# cleaned_df = merged_df.drop_duplicates(subset=['tags', 'description'], keep='first')\n",
    "# \n",
    "# # Check the new number of rows\n",
    "# print(f\"Number of rows after removing rows with exact same tags and descriptions: {cleaned_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d97176fdcec6e41a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.032673Z",
     "start_time": "2025-04-05T00:23:44.031108Z"
    }
   },
   "outputs": [],
   "source": [
    "# cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab23f567f3cc3",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79e0e24323ced210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.051095Z",
     "start_time": "2025-04-05T00:23:44.048750Z"
    }
   },
   "outputs": [],
   "source": [
    "# def remove_tags_duplicates(text):\n",
    "#     if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "#         return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "#     unique_words = sorted(set(word.strip() for word in text.split(\",\")))\n",
    "#     return ', '.join(unique_words)  # Join back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab567bbf0bba6630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.074326Z",
     "start_time": "2025-04-05T00:23:44.072168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "# final_df = cleaned_df.copy()\n",
    "# final_df[\"tags\"] = final_df[\"tags\"].progress_apply(remove_tags_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "621316ad705b04a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.086799Z",
     "start_time": "2025-04-05T00:23:44.084895Z"
    }
   },
   "outputs": [],
   "source": [
    "### Need to conduct spelling correction in description column here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56d7d5b45309149a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.096415Z",
     "start_time": "2025-04-05T00:23:44.094406Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Function to handle concatenation with empty strings and NaN values\n",
    "# def merge_descriptions(row):\n",
    "#     parts = []\n",
    "#     if pd.notna(row['description']) and row['description'].strip():\n",
    "#         parts.append(row['description'].strip())\n",
    "#     if pd.notna(row['tags']) and row['tags'].strip():\n",
    "#         parts.append(\"Tags: \" + row['tags'].strip())\n",
    "#     \n",
    "#     return \" \".join(parts)\n",
    "\n",
    "final_df = merged_df.copy()\n",
    "# Apply the function to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6e326d7226cd3d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.116569Z",
     "start_time": "2025-04-05T00:23:44.111624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     4331 non-null   object\n",
      " 1   description  4331 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.8+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd703811af1e42f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.130851Z",
     "start_time": "2025-04-05T00:23:44.127767Z"
    }
   },
   "outputs": [],
   "source": [
    "# def check_misspelled_words(text):\n",
    "#     if not isinstance(text, str) or text.strip() == \"\":\n",
    "#         return []\n",
    "# \n",
    "#     translator = str.maketrans('', '', string.punctuation)\n",
    "#     clean_text = text.translate(translator).lower()\n",
    "#     words = clean_text.split()\n",
    "# \n",
    "#     misspelled = list(spell.unknown(words))\n",
    "#     return misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18216825b2801991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.139466Z",
     "start_time": "2025-04-05T00:23:44.137081Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_df['misspelled_words'] = final_df['merged_description'].progress_apply(check_misspelled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe209e8d676d60f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.170630Z",
     "start_time": "2025-04-05T00:23:44.168918Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Filter rows where spelling_errors is not an empty list\n",
    "# rows_with_errors = final_df[final_df['misspelled_words'].apply(lambda x: bool(x))]\n",
    "# \n",
    "# rows_with_errors[\"misspelled_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a8e8e297f61204c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.175692Z",
     "start_time": "2025-04-05T00:23:44.173944Z"
    }
   },
   "outputs": [],
   "source": [
    "# count = final_df['spelling_errors'].apply(lambda x: bool(x)).sum()\n",
    "# print(f\"Number of rows with spelling errors: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5acd91e7c55a4a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.180278Z",
     "start_time": "2025-04-05T00:23:44.178548Z"
    }
   },
   "outputs": [],
   "source": [
    "# from textblob import TextBlob\n",
    "# \n",
    "# def textblob_correct(text):\n",
    "#     if not isinstance(text, str) or text.strip() == \"\":\n",
    "#         return \"\"\n",
    "#     try:\n",
    "#         blob = TextBlob(text)\n",
    "#         return str(blob.correct())\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to correct: {text[:50]}... — {e}\")\n",
    "#         return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6e448be28bfc41a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.189960Z",
     "start_time": "2025-04-05T00:23:44.187855Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_df['corrected_description'] = final_df['merged_description'].progress_apply(textblob_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2eb0a32e2620dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.203033Z",
     "start_time": "2025-04-05T00:23:44.201381Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Filter rows where spelling_errors is not an empty list\n",
    "# final_df[final_df['misspelled_words'].apply(lambda x: bool(x))][[\"corrected_description\", \"misspelled_words\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a33cb342f30a9",
   "metadata": {},
   "source": [
    "## Exploratory Business Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65a5aa09c7380dff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.223886Z",
     "start_time": "2025-04-05T00:23:44.222017Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Text Length Distribution\n",
    "# final_df[\"desc_length\"] = final_df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "# \n",
    "# plt.hist(final_df[\"desc_length\"], bins=30)\n",
    "# plt.title(\"Distribution of Description Word Counts\")\n",
    "# plt.xlabel(\"Number of Words\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f028f94fae23246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.259120Z",
     "start_time": "2025-04-05T00:23:44.257262Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Tag Frequency Analysis\n",
    "# tag_list = final_df['tags'].dropna().apply(lambda x: [tag.strip() for tag in x.split(\",\")])\n",
    "# all_tags = [tag for sublist in tag_list for tag in sublist]\n",
    "# \n",
    "# top_tags = Counter(all_tags).most_common(20)\n",
    "# \n",
    "# print(\"Top 20 tags:\")\n",
    "# print(top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f9c17bc00aa93f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.263249Z",
     "start_time": "2025-04-05T00:23:44.261262Z"
    }
   },
   "outputs": [],
   "source": [
    "# tag_df = pd.DataFrame(top_tags, columns=[\"tag\", \"count\"])\n",
    "# tag_df.plot(kind='bar', x='tag', y='count', figsize=(10,5), title=\"Top 20 Tags\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec44c0c0ae72e43e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.266313Z",
     "start_time": "2025-04-05T00:23:44.264377Z"
    }
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# \n",
    "# # Most Common Words\n",
    "# nltk.download('stopwords')\n",
    "# \n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# \n",
    "# word_list = final_df['description'].dropna().apply(lambda x: [w for w in str(x).lower().split() if w not in stop_words])\n",
    "# flat_words = [word for sublist in word_list for word in sublist]\n",
    "# \n",
    "# top_words = Counter(flat_words).most_common(20)\n",
    "# print(\"Top 20 common words:\")\n",
    "# print(top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe49ea25a063e30",
   "metadata": {},
   "source": [
    "## Embedding using Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "730ea9d04cda84e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.275893Z",
     "start_time": "2025-04-05T00:23:44.274268Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load SBERT model\n",
    "# sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# sbert_model = sbert_model.to(device)\n",
    "# \n",
    "# # Return SBERT embedding for a given text.\n",
    "# def embed_text(text):\n",
    "#     if pd.isna(text) or text.strip() == \"\":\n",
    "#         return np.zeros(384, dtype=np.float32)  # Return zero vector for missing values (SBERT output size = 384)\n",
    "#     return sbert_model.encode(text).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af47bf3aa4b70804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.280800Z",
     "start_time": "2025-04-05T00:23:44.278117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReference: https://sbert.net/\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference: https://sbert.net/\n",
    "\"\"\"\n",
    "\n",
    "# Apply SBERT embeddings to each columns\n",
    "# print(\"Embedding tags...\")\n",
    "# final_df[\"tags_embedding\"] = final_df[\"tags\"].progress_apply(embed_text)\n",
    "# \n",
    "# print(\"Embedding llm_description...\")\n",
    "# final_df[\"description_embedding\"] = final_df[\"description\"].progress_apply(embed_text)\n",
    "# print(\"Embedding text...\")\n",
    "# final_df[\"combined_embedding\"] = final_df[\"merged_description\"].progress_apply(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9743d59ccb651dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.308547Z",
     "start_time": "2025-04-05T00:23:44.305845Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Combining the embeddings\n",
    "# final_df[\"combined_embedding\"] = final_df.apply(\n",
    "#     lambda row: np.concatenate([row[\"tags_embedding\"], row[\"description_embedding\"]]), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767036b823678f24",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ef2e77f11faf36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.315302Z",
     "start_time": "2025-04-05T00:23:44.311027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cartoonized_image_0.png</td>\n",
       "      <td>a red mailbox with a white background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartoonized_image_1.png</td>\n",
       "      <td>an old car sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cartoonized_image_10.png</td>\n",
       "      <td>hot air balloon sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cartoonized_image_100.png</td>\n",
       "      <td>a sticker with a cartoon pine wearing glasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartoonized_image_1000.png</td>\n",
       "      <td>a stained stained glass window with a humming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename                                    description\n",
       "0     cartoonized_image_0.png          a red mailbox with a white background\n",
       "1     cartoonized_image_1.png                             an old car sticker\n",
       "2    cartoonized_image_10.png                        hot air balloon sticker\n",
       "3   cartoonized_image_100.png  a sticker with a cartoon pine wearing glasses\n",
       "4  cartoonized_image_1000.png  a stained stained glass window with a humming"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e55aa20576cee0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.326814Z",
     "start_time": "2025-04-05T00:23:44.321656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       cartoonized_image_0.pt\n",
       "1       cartoonized_image_1.pt\n",
       "2      cartoonized_image_10.pt\n",
       "3     cartoonized_image_100.pt\n",
       "4    cartoonized_image_1000.pt\n",
       "Name: filename, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change file extensions from .png to .pt in the 'filename' column\n",
    "final_df['filename'] = final_df['filename'].str.replace('.png', '.pt', regex=False)\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "final_df['filename'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65cea0714e1cd7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.373997Z",
     "start_time": "2025-04-05T00:23:44.348554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4331/4331 [00:00<00:00, 62338.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cartoonized_image_0.pt</td>\n",
       "      <td>a red mailbox with a white background</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cartoonized_image_1.pt</td>\n",
       "      <td>an old car sticker</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cartoonized_image_10.pt</td>\n",
       "      <td>hot air balloon sticker</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cartoonized_image_100.pt</td>\n",
       "      <td>a sticker with a cartoon pine wearing glasses</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cartoonized_image_1000.pt</td>\n",
       "      <td>a stained stained glass window with a humming</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename                                    description  \\\n",
       "0     cartoonized_image_0.pt          a red mailbox with a white background   \n",
       "1     cartoonized_image_1.pt                             an old car sticker   \n",
       "2    cartoonized_image_10.pt                        hot air balloon sticker   \n",
       "3   cartoonized_image_100.pt  a sticker with a cartoon pine wearing glasses   \n",
       "4  cartoonized_image_1000.pt  a stained stained glass window with a humming   \n",
       "\n",
       "                                          image_path  \n",
       "0  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "1  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "2  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "3  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "4  ../data/tensor_images/AlexatorStickers\\cartoon...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base directory and folders to search in\n",
    "base_dir = \"../data/tensor_images/\"\n",
    "folders = [\"AlexatorStickers\"]\n",
    "\n",
    "# Function to find the file path for a given filename\n",
    "def find_image_path(filename):\n",
    "    # Loop through each folder\n",
    "    for folder in folders:\n",
    "        # Construct full path\n",
    "        full_path = os.path.join(base_dir, folder, filename)\n",
    "        # Check if file exists at this path\n",
    "        if os.path.exists(full_path):\n",
    "            return full_path\n",
    "    # Return None if file not found in any folder\n",
    "    return None\n",
    "\n",
    "# Create the new column by applying the function to the filename column\n",
    "final_df['image_path'] = final_df['filename'].progress_apply(find_image_path)\n",
    "\n",
    "# Display a sample of the DataFrame to verify\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbcbae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.rename(columns={'description': 'prompt'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d602dddd4c890b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.394119Z",
     "start_time": "2025-04-05T00:23:44.389571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prompt</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>cartoonized_image_995.pt</td>\n",
       "      <td>a cartoon fox sitting in a field of flowers</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>cartoonized_image_996.pt</td>\n",
       "      <td>a cartoon frog sitting on a table</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>cartoonized_image_997.pt</td>\n",
       "      <td>a kangaroo playing the piano</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>cartoonized_image_998.pt</td>\n",
       "      <td>a sticker with a landscape and a butterfly</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>cartoonized_image_999.pt</td>\n",
       "      <td>flaming flaming flaming flaming flaming flamin...</td>\n",
       "      <td>../data/tensor_images/AlexatorStickers\\cartoon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  \\\n",
       "4326  cartoonized_image_995.pt   \n",
       "4327  cartoonized_image_996.pt   \n",
       "4328  cartoonized_image_997.pt   \n",
       "4329  cartoonized_image_998.pt   \n",
       "4330  cartoonized_image_999.pt   \n",
       "\n",
       "                                                 prompt  \\\n",
       "4326        a cartoon fox sitting in a field of flowers   \n",
       "4327                  a cartoon frog sitting on a table   \n",
       "4328                       a kangaroo playing the piano   \n",
       "4329         a sticker with a landscape and a butterfly   \n",
       "4330  flaming flaming flaming flaming flaming flamin...   \n",
       "\n",
       "                                             image_path  \n",
       "4326  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "4327  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "4328  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "4329  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
       "4330  ../data/tensor_images/AlexatorStickers\\cartoon...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a4c12aa4d406c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.442457Z",
     "start_time": "2025-04-05T00:23:44.438064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   filename    4331 non-null   object\n",
      " 1   prompt      4331 non-null   object\n",
      " 2   image_path  4331 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 101.6+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "908903dc82f72663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.466162Z",
     "start_time": "2025-04-05T00:23:44.458945Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df.to_parquet('../data/processed_sticker_dataset.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df88f9d460d390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T00:23:44.481118Z",
     "start_time": "2025-04-05T00:23:44.479519Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
