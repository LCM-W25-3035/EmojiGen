{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.534252Z",
     "start_time": "2025-02-09T19:29:38.493502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rajprasadshrestha/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rajprasadshrestha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rajprasadshrestha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.600140Z",
     "start_time": "2025-02-09T19:29:46.535396Z"
    }
   },
   "outputs": [],
   "source": [
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "emojipedia_df = pd.read_csv('../data/emojipedia.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.632535Z",
     "start_time": "2025-02-09T19:29:46.600795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1885/1885 [00:00<00:00, 453236.82it/s]\n",
      "100%|██████████| 5034/5034 [00:00<00:00, 1037090.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "emojipedia_df['hexcode'] = emojipedia_df['Codepoints Hex'].progress_apply(unicode_to_hex)\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.646325Z",
     "start_time": "2025-02-09T19:29:46.634847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-200D', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.652835Z",
     "start_time": "2025-02-09T19:29:46.646915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3F3    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.658360Z",
     "start_time": "2025-02-09T19:29:46.653373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3C3-1F3FD-2640-27A1           4\n",
      "1F6B6-1F3FF-2642-27A1           4\n",
      "1F6B6-1F3FF-2640-27A1           4\n",
      "1F6B6-1F3FE-2640-27A1           4\n",
      "1F6B6-1F3FC-2640-27A1           4\n",
      "                               ..\n",
      "1F9D1-1F3FC-2764-1F9D1-1F3FD    2\n",
      "1F469-1F3FF-2764-1F468-1F3FD    2\n",
      "1F9D1-1F3FD-2764-1F9D1-1F3FF    2\n",
      "1F327                           2\n",
      "2601                            2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.662455Z",
     "start_time": "2025-02-09T19:29:46.659100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "duplicate_counts = emojipedia_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.667623Z",
     "start_time": "2025-02-09T19:29:46.663084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "openmoji_df = openmoji_df[~openmoji_df.duplicated(subset=['hexcode'], keep=False)]\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.683823Z",
     "start_time": "2025-02-09T19:29:46.668128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'hexcode'\n",
    "merged_df = openmoji_df.merge(emojipedia_df, on='hexcode', how='outer')\n",
    "merged_df = merged_df.merge(llm_df, on='hexcode', how='outer')\n",
    "# Convert hexcode to lowercase\n",
    "merged_df['hexcode'] = merged_df['hexcode'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.698379Z",
     "start_time": "2025-02-09T19:29:46.686290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>Title</th>\n",
       "      <th>DescribedBy</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Codepoints Hex</th>\n",
       "      <th>character</th>\n",
       "      <th>unicode_y</th>\n",
       "      <th>short description</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>LLM description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>extras-unicode</td>\n",
       "      <td>symbol-other</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>Robert Winslow</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode           group     subgroups    annotation  tags_x  \\\n",
       "0   #️⃣  0023-20e3         symbols        keycap     keycap: #  keycap   \n",
       "1   *️⃣  002a-20e3         symbols        keycap     keycap: *  keycap   \n",
       "2     -       002d  extras-unicode  symbol-other  hyphen-minus     NaN   \n",
       "3   0️⃣  0030-20e3         symbols        keycap     keycap: 0  keycap   \n",
       "4   1️⃣  0031-20e3         symbols        keycap     keycap: 1  keycap   \n",
       "\n",
       "               openmoji_tags openmoji_author openmoji_date skintone  ...  \\\n",
       "0                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "1                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "2  hyphen, minus, dash, line  Robert Winslow    2022-12-24      NaN  ...   \n",
       "3                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "4                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "\n",
       "  Title DescribedBy  URL Description  Codepoints Hex character unicode_y  \\\n",
       "0   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "1   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "2   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "3   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "4   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "\n",
       "  short description tags_y LLM description  \n",
       "0               NaN    NaN             NaN  \n",
       "1               NaN    NaN             NaN  \n",
       "2               NaN    NaN             NaN  \n",
       "3               NaN    NaN             NaN  \n",
       "4               NaN    NaN             NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.708148Z",
     "start_time": "2025-02-09T19:29:46.698996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  4282 non-null   object \n",
      " 1   hexcode                4298 non-null   object \n",
      " 2   group                  4282 non-null   object \n",
      " 3   subgroups              4282 non-null   object \n",
      " 4   annotation             4282 non-null   object \n",
      " 5   tags_x                 1906 non-null   object \n",
      " 6   openmoji_tags          391 non-null    object \n",
      " 7   openmoji_author        4282 non-null   object \n",
      " 8   openmoji_date          4282 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              3902 non-null   object \n",
      " 14  order                  3781 non-null   float64\n",
      " 15  Group                  1885 non-null   object \n",
      " 16  Subgroup               1885 non-null   object \n",
      " 17  Emoji                  1885 non-null   object \n",
      " 18  Title                  1885 non-null   object \n",
      " 19  DescribedBy            1885 non-null   object \n",
      " 20  URL                    1885 non-null   object \n",
      " 21  Description            1885 non-null   object \n",
      " 22  Codepoints Hex         1885 non-null   object \n",
      " 23  character              2622 non-null   object \n",
      " 24  unicode_y              2622 non-null   object \n",
      " 25  short description      2622 non-null   object \n",
      " 26  tags_y                 2622 non-null   object \n",
      " 27  LLM description        2622 non-null   object \n",
      "dtypes: float64(1), object(27)\n",
      "memory usage: 940.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.713856Z",
     "start_time": "2025-02-09T19:29:46.708933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select and rename required columns\n",
    "final_df = merged_df.copy()\n",
    "final_df = final_df[['emoji', 'hexcode', 'annotation', 'tags_x', 'openmoji_tags', 'Description', 'tags_y', 'LLM description']]\n",
    "final_df.columns = [\n",
    "    'emoji', 'hexcode', 'openmoji_annotation', 'openmoji_tags_1', 'openmoji_tags_2', 'emojipedia_description', 'llm_tags', 'llm_description'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.719627Z",
     "start_time": "2025-02-09T19:29:46.714620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \n",
       "0                        NaN                    NaN      NaN             NaN  \n",
       "1                        NaN                    NaN      NaN             NaN  \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN  \n",
       "3                        NaN                    NaN      NaN             NaN  \n",
       "4                        NaN                    NaN      NaN             NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:46.722865Z",
     "start_time": "2025-02-09T19:29:46.720380Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "    # Keep only letters, numbers, spaces, * and #\n",
    "    text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatize the tokens\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ', '.join(tokens)\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = sorted(set(word.strip() for word in text.split(\",\")))\n",
    "    return ', '.join(unique_words)  # Join back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.573566Z",
     "start_time": "2025-02-09T19:29:46.723564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:01<00:00, 3355.59it/s]\n",
      "100%|██████████| 4298/4298 [00:00<00:00, 1838188.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Clean openmoji_annotation column\n",
    "final_df[\"cleaned_annotations\"] = final_df[\"openmoji_annotation\"].progress_apply(clean_text)\n",
    "# Clean llm_tags\n",
    "final_df[\"cleaned_llm_tags\"] = final_df[\"llm_tags\"].progress_apply(clean_text)\n",
    "\n",
    "# List of columns to merge\n",
    "columns_to_merge = [\"cleaned_annotations\", \"openmoji_tags_1\", \"openmoji_tags_2\", \"cleaned_llm_tags\"]\n",
    "\n",
    "# Fill NaN with empty strings, then merge columns\n",
    "final_df[\"merged_tags\"] = final_df[columns_to_merge].fillna(\"\").agg(\n",
    "    lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.587090Z",
     "start_time": "2025-02-09T19:29:47.574381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 191458.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "final_df[\"final_tags\"] = final_df[\"merged_tags\"].progress_apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.601974Z",
     "start_time": "2025-02-09T19:29:47.588059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 207913.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Limiting only 2 sentences because the content is too long with too many references to other emoji, which might be more confusing later for the model to learn.\n",
    "\n",
    "\"\"\"\n",
    "Reference: Chat-GPT-4o\n",
    "Prompt: My df_images has a emojipedia_description column. Only keep the first two sentences in the column and remove the rest.\n",
    "\"\"\"\n",
    "# Function to keep only the first two sentences\n",
    "def keep_first_two_sentences(description):\n",
    "    if pd.isna(description):  # Handle missing values (NaNs)\n",
    "        return description\n",
    "    sentences = re.split(r'(?<=[.!?]) +', description.strip())  # Split by sentence-ending punctuation (., !, ?)\n",
    "    return ' '.join(sentences[:2])  # Return only the first two sentences\n",
    "\n",
    "# Apply the function to the 'llm_description' column\n",
    "final_df['emojipedia_description'] = final_df['emojipedia_description'].progress_apply(keep_first_two_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.607647Z",
     "start_time": "2025-02-09T19:29:47.602598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, #</td>\n",
       "      <td></td>\n",
       "      <td>keycap, #, keycap</td>\n",
       "      <td>#, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, *</td>\n",
       "      <td></td>\n",
       "      <td>keycap, *, keycap</td>\n",
       "      <td>*, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphenminus</td>\n",
       "      <td></td>\n",
       "      <td>hyphenminus, hyphen, minus, dash, line</td>\n",
       "      <td>dash, hyphen, hyphenminus, line, minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 0</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 0, keycap</td>\n",
       "      <td>0, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 1</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 1, keycap</td>\n",
       "      <td>1, keycap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \\\n",
       "0                        NaN                    NaN      NaN             NaN   \n",
       "1                        NaN                    NaN      NaN             NaN   \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN   \n",
       "3                        NaN                    NaN      NaN             NaN   \n",
       "4                        NaN                    NaN      NaN             NaN   \n",
       "\n",
       "  cleaned_annotations cleaned_llm_tags  \\\n",
       "0           keycap, #                    \n",
       "1           keycap, *                    \n",
       "2         hyphenminus                    \n",
       "3           keycap, 0                    \n",
       "4           keycap, 1                    \n",
       "\n",
       "                              merged_tags  \\\n",
       "0                       keycap, #, keycap   \n",
       "1                       keycap, *, keycap   \n",
       "2  hyphenminus, hyphen, minus, dash, line   \n",
       "3                       keycap, 0, keycap   \n",
       "4                       keycap, 1, keycap   \n",
       "\n",
       "                               final_tags  \n",
       "0                               #, keycap  \n",
       "1                               *, keycap  \n",
       "2  dash, hyphen, hyphenminus, line, minus  \n",
       "3                               0, keycap  \n",
       "4                               1, keycap  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.614939Z",
     "start_time": "2025-02-09T19:29:47.608424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   emoji                   4282 non-null   object\n",
      " 1   hexcode                 4298 non-null   object\n",
      " 2   openmoji_annotation     4282 non-null   object\n",
      " 3   openmoji_tags_1         1906 non-null   object\n",
      " 4   openmoji_tags_2         391 non-null    object\n",
      " 5   emojipedia_description  1885 non-null   object\n",
      " 6   llm_tags                2622 non-null   object\n",
      " 7   llm_description         2622 non-null   object\n",
      " 8   cleaned_annotations     4298 non-null   object\n",
      " 9   cleaned_llm_tags        4298 non-null   object\n",
      " 10  merged_tags             4298 non-null   object\n",
      " 11  final_tags              4298 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 403.1+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding using Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:47.641956Z",
     "start_time": "2025-02-09T19:29:47.615846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mac GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:29:49.665187Z",
     "start_time": "2025-02-09T19:29:47.642971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load SBERT model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_model = sbert_model.to(device)\n",
    "\n",
    "# Ensure text columns are strings\n",
    "# final_df[\"emojipedia_description\"] = final_df[\"emojipedia_description\"].fillna(\"\").astype(str)\n",
    "# final_df[\"llm_description\"] = final_df[\"llm_description\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Return SBERT embedding for a given text.\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return np.zeros(384)  # Return zero vector for missing values (SBERT output size = 384)\n",
    "    return sbert_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:25.059992Z",
     "start_time": "2025-02-09T19:29:49.683707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding final_tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 23/4298 [00:00<01:59, 35.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:41<00:00, 104.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding emojipedia_description...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:15<00:00, 283.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding llm_description...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:20<00:00, 207.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference: https://sbert.net/\n",
    "\"\"\"\n",
    "\n",
    "# Apply SBERT embeddings to each columns\n",
    "print(\"Embedding final_tags...\")\n",
    "final_df[\"tags_embedding\"] = final_df[\"final_tags\"].progress_apply(embed_text)\n",
    "\n",
    "print(\"Embedding emojipedia_description...\")\n",
    "final_df[\"emojipedia_embedding\"] = final_df[\"emojipedia_description\"].progress_apply(embed_text)\n",
    "\n",
    "print(\"Embedding llm_description...\")\n",
    "final_df[\"llm_embedding\"] = final_df[\"llm_description\"].progress_apply(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:25.121481Z",
     "start_time": "2025-02-09T19:31:25.062595Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df[\"combined_embedding\"] = final_df.apply(\n",
    "    lambda row: np.concatenate([row[\"tags_embedding\"], row[\"emojipedia_embedding\"], row[\"llm_embedding\"]]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:25.134456Z",
     "start_time": "2025-02-09T19:31:25.122320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>tags_embedding</th>\n",
       "      <th>emojipedia_embedding</th>\n",
       "      <th>llm_embedding</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, #</td>\n",
       "      <td></td>\n",
       "      <td>keycap, #, keycap</td>\n",
       "      <td>#, keycap</td>\n",
       "      <td>[0.02519471, -0.04989285, 0.04940779, -0.01256...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02519471012055874, -0.0498928502202034, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, *</td>\n",
       "      <td></td>\n",
       "      <td>keycap, *, keycap</td>\n",
       "      <td>*, keycap</td>\n",
       "      <td>[0.030324753, -0.047731012, 0.04585727, -0.008...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.030324753373861313, -0.04773101210594177, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphenminus</td>\n",
       "      <td></td>\n",
       "      <td>hyphenminus, hyphen, minus, dash, line</td>\n",
       "      <td>dash, hyphen, hyphenminus, line, minus</td>\n",
       "      <td>[-0.024587138, 0.10079276, 0.011220697, -0.040...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02458713762462139, 0.10079275816679001, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 0</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 0, keycap</td>\n",
       "      <td>0, keycap</td>\n",
       "      <td>[0.043693572, -0.01632516, -0.030014936, 0.029...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.04369357228279114, -0.01632516086101532, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 1</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 1, keycap</td>\n",
       "      <td>1, keycap</td>\n",
       "      <td>[0.022134297, -0.07334993, -0.0056481804, -0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.022134296596050262, -0.07334993034601212, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \\\n",
       "0                        NaN                    NaN      NaN             NaN   \n",
       "1                        NaN                    NaN      NaN             NaN   \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN   \n",
       "3                        NaN                    NaN      NaN             NaN   \n",
       "4                        NaN                    NaN      NaN             NaN   \n",
       "\n",
       "  cleaned_annotations cleaned_llm_tags  \\\n",
       "0           keycap, #                    \n",
       "1           keycap, *                    \n",
       "2         hyphenminus                    \n",
       "3           keycap, 0                    \n",
       "4           keycap, 1                    \n",
       "\n",
       "                              merged_tags  \\\n",
       "0                       keycap, #, keycap   \n",
       "1                       keycap, *, keycap   \n",
       "2  hyphenminus, hyphen, minus, dash, line   \n",
       "3                       keycap, 0, keycap   \n",
       "4                       keycap, 1, keycap   \n",
       "\n",
       "                               final_tags  \\\n",
       "0                               #, keycap   \n",
       "1                               *, keycap   \n",
       "2  dash, hyphen, hyphenminus, line, minus   \n",
       "3                               0, keycap   \n",
       "4                               1, keycap   \n",
       "\n",
       "                                      tags_embedding  \\\n",
       "0  [0.02519471, -0.04989285, 0.04940779, -0.01256...   \n",
       "1  [0.030324753, -0.047731012, 0.04585727, -0.008...   \n",
       "2  [-0.024587138, 0.10079276, 0.011220697, -0.040...   \n",
       "3  [0.043693572, -0.01632516, -0.030014936, 0.029...   \n",
       "4  [0.022134297, -0.07334993, -0.0056481804, -0.0...   \n",
       "\n",
       "                                emojipedia_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                       llm_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  combined_embedding  \n",
       "0  [0.02519471012055874, -0.0498928502202034, 0.0...  \n",
       "1  [0.030324753373861313, -0.04773101210594177, 0...  \n",
       "2  [-0.02458713762462139, 0.10079275816679001, 0....  \n",
       "3  [0.04369357228279114, -0.01632516086101532, -0...  \n",
       "4  [0.022134296596050262, -0.07334993034601212, -...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:51.323238Z",
     "start_time": "2025-02-09T19:31:25.135084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:23<00:00, 185.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "processed_image_path = \"../data/tensor_images/\"\n",
    "brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"OpenMojiEmoji\", \"TwitterEmoji\"]\n",
    "\n",
    "# Function to get image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "\n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(processed_image_path, brand)\n",
    "        if not os.path.exists(brand_path):\n",
    "            continue  # Skip if folder doesn't exist\n",
    "\n",
    "        # List all files in the category\n",
    "        matching_files = [f for f in os.listdir(brand_path) if hexcode in f]  # Match anywhere in the filename\n",
    "        \n",
    "        if matching_files:\n",
    "            # Take the first match (if multiple exist)\n",
    "            image_paths[brand] = os.path.join(brand_path, matching_files[0])\n",
    "        else:\n",
    "            image_paths[brand] = None  # No matching file found\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "df_images = final_df.copy()  # Work on a copy to be safe\n",
    "\n",
    "# Apply the function to get image paths for each row\n",
    "df_images[['google_image_path', 'joypixels_image_path', 'openmoji_image_path', 'twitter_image_path']] = df_images['hexcode'].progress_apply(lambda x: pd.Series(get_image_paths(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:51.342475Z",
     "start_time": "2025-02-09T19:31:51.324044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>tags_embedding</th>\n",
       "      <th>emojipedia_embedding</th>\n",
       "      <th>llm_embedding</th>\n",
       "      <th>combined_embedding</th>\n",
       "      <th>google_image_path</th>\n",
       "      <th>joypixels_image_path</th>\n",
       "      <th>openmoji_image_path</th>\n",
       "      <th>twitter_image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, #</td>\n",
       "      <td></td>\n",
       "      <td>keycap, #, keycap</td>\n",
       "      <td>#, keycap</td>\n",
       "      <td>[0.02519471, -0.04989285, 0.04940779, -0.01256...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02519471012055874, -0.0498928502202034, 0.0...</td>\n",
       "      <td>../data/tensor_images/GoogleEmoji/0023-20e3.pt</td>\n",
       "      <td>../data/tensor_images/JoyPixelsEmoji/0023-20e3.pt</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/0023-20e3.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, *</td>\n",
       "      <td></td>\n",
       "      <td>keycap, *, keycap</td>\n",
       "      <td>*, keycap</td>\n",
       "      <td>[0.030324753, -0.047731012, 0.04585727, -0.008...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.030324753373861313, -0.04773101210594177, 0...</td>\n",
       "      <td>../data/tensor_images/GoogleEmoji/002a-20e3.pt</td>\n",
       "      <td>../data/tensor_images/JoyPixelsEmoji/002a-20e3.pt</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/002a-20e3.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphenminus</td>\n",
       "      <td></td>\n",
       "      <td>hyphenminus, hyphen, minus, dash, line</td>\n",
       "      <td>dash, hyphen, hyphenminus, line, minus</td>\n",
       "      <td>[-0.024587138, 0.10079276, 0.011220697, -0.040...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.02458713762462139, 0.10079275816679001, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/002d.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 0</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 0, keycap</td>\n",
       "      <td>0, keycap</td>\n",
       "      <td>[0.043693572, -0.01632516, -0.030014936, 0.029...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.04369357228279114, -0.01632516086101532, -0...</td>\n",
       "      <td>../data/tensor_images/GoogleEmoji/0030-20e3.pt</td>\n",
       "      <td>../data/tensor_images/JoyPixelsEmoji/0030-20e3.pt</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/0030-20e3.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 1</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 1, keycap</td>\n",
       "      <td>1, keycap</td>\n",
       "      <td>[0.022134297, -0.07334993, -0.0056481804, -0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.022134296596050262, -0.07334993034601212, -...</td>\n",
       "      <td>../data/tensor_images/GoogleEmoji/0031-20e3.pt</td>\n",
       "      <td>../data/tensor_images/JoyPixelsEmoji/0031-20e3.pt</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/0031-20e3.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td></td>\n",
       "      <td>e380</td>\n",
       "      <td>no handshaking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hygiene, agreement, virus, meeting, spread, germs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>handshaking</td>\n",
       "      <td></td>\n",
       "      <td>handshaking, hygiene, agreement, virus, meetin...</td>\n",
       "      <td>agreement, germs, handshaking, hygiene, meetin...</td>\n",
       "      <td>[0.02637571, 0.066247724, -0.0017016777, -0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02637570910155773, 0.06624772399663925, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/e380.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td></td>\n",
       "      <td>e381</td>\n",
       "      <td>web syndication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feed, RSS, atom feed, podcast, subscribe, web ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>web, syndication</td>\n",
       "      <td></td>\n",
       "      <td>web, syndication, feed, RSS, atom feed, podcas...</td>\n",
       "      <td>RSS, atom feed, feed, podcast, subscribe, synd...</td>\n",
       "      <td>[0.025086876, -0.12783332, -0.050925713, -0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02508687600493431, -0.1278333216905594, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/e381.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td></td>\n",
       "      <td>f000</td>\n",
       "      <td>windows</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>windows</td>\n",
       "      <td></td>\n",
       "      <td>windows, Microsoft</td>\n",
       "      <td>Microsoft, windows</td>\n",
       "      <td>[-0.0010178613, -0.015280813, -0.03865494, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.0010178613010793924, -0.015280812978744507...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/f000.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td></td>\n",
       "      <td>f77a</td>\n",
       "      <td>artstation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>art, brand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artstation</td>\n",
       "      <td></td>\n",
       "      <td>artstation, art, brand</td>\n",
       "      <td>art, artstation, brand</td>\n",
       "      <td>[0.026021712, -0.005451154, 0.024167942, -0.07...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02602171152830124, -0.005451153963804245, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/f77a.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td></td>\n",
       "      <td>f8ff</td>\n",
       "      <td>apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iOS, OSX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apple</td>\n",
       "      <td></td>\n",
       "      <td>apple, iOS, OSX</td>\n",
       "      <td>OSX, apple, iOS</td>\n",
       "      <td>[0.02274738, -0.075784504, 0.07421439, -0.0618...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.022747380658984184, -0.07578450441360474, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/f8ff.pt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4298 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0      #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1      *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2        -       002d        hyphen-minus             NaN   \n",
       "3      0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4      1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "...    ...        ...                 ...             ...   \n",
       "4293            e380      no handshaking             NaN   \n",
       "4294            e381     web syndication             NaN   \n",
       "4295            f000             windows             NaN   \n",
       "4296            f77a          artstation             NaN   \n",
       "4297            f8ff               apple             NaN   \n",
       "\n",
       "                                        openmoji_tags_2  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                             hyphen, minus, dash, line   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4293  hygiene, agreement, virus, meeting, spread, germs   \n",
       "4294  feed, RSS, atom feed, podcast, subscribe, web ...   \n",
       "4295                                          Microsoft   \n",
       "4296                                         art, brand   \n",
       "4297                                           iOS, OSX   \n",
       "\n",
       "     emojipedia_description llm_tags llm_description cleaned_annotations  \\\n",
       "0                       NaN      NaN             NaN           keycap, #   \n",
       "1                       NaN      NaN             NaN           keycap, *   \n",
       "2                       NaN      NaN             NaN         hyphenminus   \n",
       "3                       NaN      NaN             NaN           keycap, 0   \n",
       "4                       NaN      NaN             NaN           keycap, 1   \n",
       "...                     ...      ...             ...                 ...   \n",
       "4293                    NaN      NaN             NaN         handshaking   \n",
       "4294                    NaN      NaN             NaN    web, syndication   \n",
       "4295                    NaN      NaN             NaN             windows   \n",
       "4296                    NaN      NaN             NaN          artstation   \n",
       "4297                    NaN      NaN             NaN               apple   \n",
       "\n",
       "     cleaned_llm_tags                                        merged_tags  \\\n",
       "0                                                      keycap, #, keycap   \n",
       "1                                                      keycap, *, keycap   \n",
       "2                                 hyphenminus, hyphen, minus, dash, line   \n",
       "3                                                      keycap, 0, keycap   \n",
       "4                                                      keycap, 1, keycap   \n",
       "...               ...                                                ...   \n",
       "4293                   handshaking, hygiene, agreement, virus, meetin...   \n",
       "4294                   web, syndication, feed, RSS, atom feed, podcas...   \n",
       "4295                                                  windows, Microsoft   \n",
       "4296                                              artstation, art, brand   \n",
       "4297                                                     apple, iOS, OSX   \n",
       "\n",
       "                                             final_tags  \\\n",
       "0                                             #, keycap   \n",
       "1                                             *, keycap   \n",
       "2                dash, hyphen, hyphenminus, line, minus   \n",
       "3                                             0, keycap   \n",
       "4                                             1, keycap   \n",
       "...                                                 ...   \n",
       "4293  agreement, germs, handshaking, hygiene, meetin...   \n",
       "4294  RSS, atom feed, feed, podcast, subscribe, synd...   \n",
       "4295                                 Microsoft, windows   \n",
       "4296                             art, artstation, brand   \n",
       "4297                                    OSX, apple, iOS   \n",
       "\n",
       "                                         tags_embedding  \\\n",
       "0     [0.02519471, -0.04989285, 0.04940779, -0.01256...   \n",
       "1     [0.030324753, -0.047731012, 0.04585727, -0.008...   \n",
       "2     [-0.024587138, 0.10079276, 0.011220697, -0.040...   \n",
       "3     [0.043693572, -0.01632516, -0.030014936, 0.029...   \n",
       "4     [0.022134297, -0.07334993, -0.0056481804, -0.0...   \n",
       "...                                                 ...   \n",
       "4293  [0.02637571, 0.066247724, -0.0017016777, -0.02...   \n",
       "4294  [0.025086876, -0.12783332, -0.050925713, -0.03...   \n",
       "4295  [-0.0010178613, -0.015280813, -0.03865494, 0.0...   \n",
       "4296  [0.026021712, -0.005451154, 0.024167942, -0.07...   \n",
       "4297  [0.02274738, -0.075784504, 0.07421439, -0.0618...   \n",
       "\n",
       "                                   emojipedia_embedding  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "4293  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4294  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4295  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4296  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4297  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                          llm_embedding  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "4293  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4294  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4295  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4296  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4297  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     combined_embedding  \\\n",
       "0     [0.02519471012055874, -0.0498928502202034, 0.0...   \n",
       "1     [0.030324753373861313, -0.04773101210594177, 0...   \n",
       "2     [-0.02458713762462139, 0.10079275816679001, 0....   \n",
       "3     [0.04369357228279114, -0.01632516086101532, -0...   \n",
       "4     [0.022134296596050262, -0.07334993034601212, -...   \n",
       "...                                                 ...   \n",
       "4293  [0.02637570910155773, 0.06624772399663925, -0....   \n",
       "4294  [0.02508687600493431, -0.1278333216905594, -0....   \n",
       "4295  [-0.0010178613010793924, -0.015280812978744507...   \n",
       "4296  [0.02602171152830124, -0.005451153963804245, 0...   \n",
       "4297  [0.022747380658984184, -0.07578450441360474, 0...   \n",
       "\n",
       "                                   google_image_path  \\\n",
       "0     ../data/tensor_images/GoogleEmoji/0023-20e3.pt   \n",
       "1     ../data/tensor_images/GoogleEmoji/002a-20e3.pt   \n",
       "2                                               None   \n",
       "3     ../data/tensor_images/GoogleEmoji/0030-20e3.pt   \n",
       "4     ../data/tensor_images/GoogleEmoji/0031-20e3.pt   \n",
       "...                                              ...   \n",
       "4293                                            None   \n",
       "4294                                            None   \n",
       "4295                                            None   \n",
       "4296                                            None   \n",
       "4297                                            None   \n",
       "\n",
       "                                   joypixels_image_path  \\\n",
       "0     ../data/tensor_images/JoyPixelsEmoji/0023-20e3.pt   \n",
       "1     ../data/tensor_images/JoyPixelsEmoji/002a-20e3.pt   \n",
       "2                                                  None   \n",
       "3     ../data/tensor_images/JoyPixelsEmoji/0030-20e3.pt   \n",
       "4     ../data/tensor_images/JoyPixelsEmoji/0031-20e3.pt   \n",
       "...                                                 ...   \n",
       "4293                                               None   \n",
       "4294                                               None   \n",
       "4295                                               None   \n",
       "4296                                               None   \n",
       "4297                                               None   \n",
       "\n",
       "                                   openmoji_image_path twitter_image_path  \n",
       "0     ../data/tensor_images/OpenMojiEmoji/0023-20e3.pt               None  \n",
       "1     ../data/tensor_images/OpenMojiEmoji/002a-20e3.pt               None  \n",
       "2          ../data/tensor_images/OpenMojiEmoji/002d.pt               None  \n",
       "3     ../data/tensor_images/OpenMojiEmoji/0030-20e3.pt               None  \n",
       "4     ../data/tensor_images/OpenMojiEmoji/0031-20e3.pt               None  \n",
       "...                                                ...                ...  \n",
       "4293       ../data/tensor_images/OpenMojiEmoji/e380.pt               None  \n",
       "4294       ../data/tensor_images/OpenMojiEmoji/e381.pt               None  \n",
       "4295       ../data/tensor_images/OpenMojiEmoji/f000.pt               None  \n",
       "4296       ../data/tensor_images/OpenMojiEmoji/f77a.pt               None  \n",
       "4297       ../data/tensor_images/OpenMojiEmoji/f8ff.pt               None  \n",
       "\n",
       "[4298 rows x 20 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:51.350109Z",
     "start_time": "2025-02-09T19:31:51.343396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   emoji                   4282 non-null   object\n",
      " 1   hexcode                 4298 non-null   object\n",
      " 2   openmoji_annotation     4282 non-null   object\n",
      " 3   openmoji_tags_1         1906 non-null   object\n",
      " 4   openmoji_tags_2         391 non-null    object\n",
      " 5   emojipedia_description  1885 non-null   object\n",
      " 6   llm_tags                2622 non-null   object\n",
      " 7   llm_description         2622 non-null   object\n",
      " 8   cleaned_annotations     4298 non-null   object\n",
      " 9   cleaned_llm_tags        4298 non-null   object\n",
      " 10  merged_tags             4298 non-null   object\n",
      " 11  final_tags              4298 non-null   object\n",
      " 12  tags_embedding          4298 non-null   object\n",
      " 13  emojipedia_embedding    4298 non-null   object\n",
      " 14  llm_embedding           4298 non-null   object\n",
      " 15  combined_embedding      4298 non-null   object\n",
      " 16  google_image_path       3562 non-null   object\n",
      " 17  joypixels_image_path    3824 non-null   object\n",
      " 18  openmoji_image_path     4297 non-null   object\n",
      " 19  twitter_image_path      871 non-null    object\n",
      "dtypes: object(20)\n",
      "memory usage: 671.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_images.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T19:31:51.355674Z",
     "start_time": "2025-02-09T19:31:51.354216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|██████████| 4298/4298 [00:22<00:00, 194.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference: Chat-GPT-4o\n",
    "Prompt: \n",
    " \n",
    "This is my final_df.\n",
    "\n",
    "\n",
    "#   Column\n",
    "\n",
    "---  ------\n",
    "\n",
    " 0   hexcode\n",
    "\n",
    " 1  combined_embedding\n",
    "\n",
    "\n",
    "\n",
    "I need to get image path of a specific emoji and add it to the dataframe in a new column \"image_path\". My images are in the path \"../data/tensor_images/\". I have emojis of 4 different brands in their respective folders inside the image path [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"OpenMojiEmoji\", \"TwitterEmoji\"]. I want a new row for each image. Some brands have emoji specific to the hex code, and some do not.\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"OpenMojiEmoji\", \"TwitterEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "   \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "           \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "       \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(final_df.iterrows(), total=len(final_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "   \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12510 entries, 0 to 12509\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             12510 non-null  object\n",
      " 1   combined_embedding  12510 non-null  object\n",
      " 2   image_path          12510 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 293.3+ KB\n"
     ]
    }
   ],
   "source": [
    "expanded_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [100/391], D Loss: 0.18671101331710815, G Loss: 4.123954772949219\n",
      "Epoch [1/4], Step [200/391], D Loss: 0.3518197536468506, G Loss: 2.5185885429382324\n",
      "Epoch [1/4], Step [300/391], D Loss: 0.6162877082824707, G Loss: 6.8570404052734375\n",
      "Epoch [2/4], Step [100/391], D Loss: 0.4212099313735962, G Loss: 2.4823451042175293\n",
      "Epoch [2/4], Step [200/391], D Loss: 1.1088223457336426, G Loss: 1.679426670074463\n",
      "Epoch [2/4], Step [300/391], D Loss: 0.7740771770477295, G Loss: 2.6906867027282715\n",
      "Epoch [3/4], Step [100/391], D Loss: 0.46282222867012024, G Loss: 2.1670422554016113\n",
      "Epoch [3/4], Step [200/391], D Loss: 0.6897350549697876, G Loss: 1.7810333967208862\n",
      "Epoch [3/4], Step [300/391], D Loss: 0.7655010223388672, G Loss: 2.8216466903686523\n",
      "Epoch [4/4], Step [100/391], D Loss: 0.8151779174804688, G Loss: 1.8335931301116943\n",
      "Epoch [4/4], Step [200/391], D Loss: 0.5846915245056152, G Loss: 1.9725338220596313\n",
      "Epoch [4/4], Step [300/391], D Loss: 0.45163917541503906, G Loss: 2.606194496154785\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Reference: Chat-GPT-4o\n",
    "# Prompt: Build a GAN model to generate emoji images based on their embeddings. The dataset contains the following columns: 'combined_embedding', 'image_path'. The 'combined_embedding' column contains the combined embeddings of tags, emojipedia description, and LLM description. The 'image_path' column contains the path to the image tensor. The model should have a generator and a discriminator. The generator should take the combined embedding as input and output an image tensor. The discriminator should take an image tensor and the combined embedding as input and output a probability score. Train the GAN model on the dataset for a few epochs.\"\"\"\n",
    "# \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the dataset class\n",
    "class EmojiDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        embedding = row['combined_embedding']\n",
    "        \n",
    "        # Load the image tensor\n",
    "        image_tensor = torch.load(image_path)\n",
    "        \n",
    "        # Convert embedding to tensor\n",
    "        embedding_tensor = torch.tensor(embedding, dtype=torch.float32)\n",
    "        \n",
    "        return embedding_tensor, image_tensor\n",
    "\n",
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, embedding_dim, image_channels, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, image_channels * image_size * image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.image_channels = image_channels\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.image_channels, self.image_size, self.image_size)\n",
    "        return x\n",
    "\n",
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels, image_size, embedding_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.image_channels = image_channels\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(image_channels * image_size * image_size + embedding_dim, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, embedding):\n",
    "        image_flat = image.view(-1, self.image_channels * self.image_size * self.image_size)\n",
    "        x = torch.cat((image_flat, embedding), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 384 * 3  # Combined embedding dimension\n",
    "image_channels = 3  # Assuming RGB images\n",
    "image_size = 16  # Assuming 64x64 images\n",
    "batch_size = 32\n",
    "num_epochs = 4\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = EmojiDataset(expanded_df)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(embedding_dim, image_channels, image_size).to(device)\n",
    "discriminator = Discriminator(image_channels, image_size, embedding_dim).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (embeddings, real_images) in enumerate(dataloader):\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        outputs = discriminator(real_images.to(device), embeddings.to(device))\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "        \n",
    "        z = torch.randn(batch_size, embedding_dim).to(device)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images.detach(), embeddings.to(device))\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, embedding_dim).to(device)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images, embeddings.to(device))\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Generator.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m embedding_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(text_embedding, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Generate an image\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m generated_image\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Display the generated image\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: Generator.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# For the text \"smiling face\" do the embeddings and generate an emoji\n",
    "text = \"smiling face\"\n",
    "\n",
    "# Embed the text\n",
    "text_embedding = embed_text(text)\n",
    "\n",
    "# Generate a noise tensor\n",
    "noise = torch.randn(1, noise_dim).to(device)\n",
    "\n",
    "# Convert text embedding to tensor and add batch dimension\n",
    "embedding_tensor = torch.tensor(text_embedding, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "\n",
    "# Generate an image\n",
    "generated_image = generator(noise, embedding_tensor)\n",
    "generated_image = generated_image.squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "# Display the generated image\n",
    "plt.imshow(generated_image.transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
