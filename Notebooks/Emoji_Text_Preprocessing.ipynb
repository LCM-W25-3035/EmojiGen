{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.268774Z",
     "start_time": "2025-02-13T14:37:21.238759Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.397643Z",
     "start_time": "2025-02-13T14:37:21.289415Z"
    }
   },
   "source": [
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "emojipedia_df = pd.read_csv('../data/emojipedia.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.414526Z",
     "start_time": "2025-02-13T14:37:21.398825Z"
    }
   },
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "emojipedia_df['hexcode'] = emojipedia_df['Codepoints Hex'].progress_apply(unicode_to_hex)\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1885/1885 [00:00<00:00, 1090819.96it/s]\n",
      "100%|██████████| 5034/5034 [00:00<00:00, 1228065.28it/s]\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.438585Z",
     "start_time": "2025-02-13T14:37:21.415202Z"
    }
   },
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-200D', '', regex=True)"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.452961Z",
     "start_time": "2025-02-13T14:37:21.446Z"
    }
   },
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3F3    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.458779Z",
     "start_time": "2025-02-13T14:37:21.453845Z"
    }
   },
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3C3-1F3FD-2640-27A1           4\n",
      "1F6B6-1F3FF-2642-27A1           4\n",
      "1F6B6-1F3FF-2640-27A1           4\n",
      "1F6B6-1F3FE-2640-27A1           4\n",
      "1F6B6-1F3FC-2640-27A1           4\n",
      "                               ..\n",
      "1F9D1-1F3FC-2764-1F9D1-1F3FD    2\n",
      "1F469-1F3FF-2764-1F468-1F3FD    2\n",
      "1F9D1-1F3FD-2764-1F9D1-1F3FF    2\n",
      "1F327                           2\n",
      "2601                            2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.462280Z",
     "start_time": "2025-02-13T14:37:21.459425Z"
    }
   },
   "source": [
    "duplicate_counts = emojipedia_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.470566Z",
     "start_time": "2025-02-13T14:37:21.463365Z"
    }
   },
   "source": [
    "# Removing duplicates\n",
    "openmoji_df = openmoji_df[~openmoji_df.duplicated(subset=['hexcode'], keep=False)]\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.488934Z",
     "start_time": "2025-02-13T14:37:21.471325Z"
    }
   },
   "source": [
    "# Merge the dataframes on 'hexcode'\n",
    "merged_df = openmoji_df.merge(emojipedia_df, on='hexcode', how='outer')\n",
    "merged_df = merged_df.merge(llm_df, on='hexcode', how='outer')\n",
    "# Convert hexcode to lowercase\n",
    "merged_df['hexcode'] = merged_df['hexcode'].str.lower()"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.498683Z",
     "start_time": "2025-02-13T14:37:21.490164Z"
    }
   },
   "source": [
    "merged_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  emoji    hexcode           group     subgroups    annotation  tags_x  \\\n",
       "0   #️⃣  0023-20e3         symbols        keycap     keycap: #  keycap   \n",
       "1   *️⃣  002a-20e3         symbols        keycap     keycap: *  keycap   \n",
       "2     -       002d  extras-unicode  symbol-other  hyphen-minus     NaN   \n",
       "3   0️⃣  0030-20e3         symbols        keycap     keycap: 0  keycap   \n",
       "4   1️⃣  0031-20e3         symbols        keycap     keycap: 1  keycap   \n",
       "\n",
       "               openmoji_tags openmoji_author openmoji_date skintone  ...  \\\n",
       "0                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "1                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "2  hyphen, minus, dash, line  Robert Winslow    2022-12-24      NaN  ...   \n",
       "3                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "4                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "\n",
       "  Title DescribedBy  URL Description  Codepoints Hex character unicode_y  \\\n",
       "0   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "1   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "2   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "3   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "4   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "\n",
       "  short description tags_y LLM description  \n",
       "0               NaN    NaN             NaN  \n",
       "1               NaN    NaN             NaN  \n",
       "2               NaN    NaN             NaN  \n",
       "3               NaN    NaN             NaN  \n",
       "4               NaN    NaN             NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>Title</th>\n",
       "      <th>DescribedBy</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Codepoints Hex</th>\n",
       "      <th>character</th>\n",
       "      <th>unicode_y</th>\n",
       "      <th>short description</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>LLM description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>extras-unicode</td>\n",
       "      <td>symbol-other</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>Robert Winslow</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.510543Z",
     "start_time": "2025-02-13T14:37:21.500790Z"
    }
   },
   "source": [
    "merged_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  4282 non-null   object \n",
      " 1   hexcode                4298 non-null   object \n",
      " 2   group                  4282 non-null   object \n",
      " 3   subgroups              4282 non-null   object \n",
      " 4   annotation             4282 non-null   object \n",
      " 5   tags_x                 1906 non-null   object \n",
      " 6   openmoji_tags          391 non-null    object \n",
      " 7   openmoji_author        4282 non-null   object \n",
      " 8   openmoji_date          4282 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              3902 non-null   object \n",
      " 14  order                  3781 non-null   float64\n",
      " 15  Group                  1885 non-null   object \n",
      " 16  Subgroup               1885 non-null   object \n",
      " 17  Emoji                  1885 non-null   object \n",
      " 18  Title                  1885 non-null   object \n",
      " 19  DescribedBy            1885 non-null   object \n",
      " 20  URL                    1885 non-null   object \n",
      " 21  Description            1885 non-null   object \n",
      " 22  Codepoints Hex         1885 non-null   object \n",
      " 23  character              2622 non-null   object \n",
      " 24  unicode_y              2622 non-null   object \n",
      " 25  short description      2622 non-null   object \n",
      " 26  tags_y                 2622 non-null   object \n",
      " 27  LLM description        2622 non-null   object \n",
      "dtypes: float64(1), object(27)\n",
      "memory usage: 940.3+ KB\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.516719Z",
     "start_time": "2025-02-13T14:37:21.511380Z"
    }
   },
   "source": [
    "# Select and rename required columns\n",
    "final_df = merged_df.copy()\n",
    "final_df = final_df[['emoji', 'hexcode', 'annotation', 'tags_x', 'openmoji_tags', 'Description', 'tags_y', 'LLM description']]\n",
    "final_df.columns = [\n",
    "    'emoji', 'hexcode', 'openmoji_annotation', 'openmoji_tags_1', 'openmoji_tags_2', 'emojipedia_description', 'llm_tags', 'llm_description'\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.521066Z",
     "start_time": "2025-02-13T14:37:21.517317Z"
    }
   },
   "source": [
    "final_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \n",
       "0                        NaN                    NaN      NaN             NaN  \n",
       "1                        NaN                    NaN      NaN             NaN  \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN  \n",
       "3                        NaN                    NaN      NaN             NaN  \n",
       "4                        NaN                    NaN      NaN             NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:21.524752Z",
     "start_time": "2025-02-13T14:37:21.521773Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "    # Keep only letters, numbers, spaces, * and #\n",
    "    text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatize the tokens\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ', '.join(tokens)\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = sorted(set(word.strip() for word in text.split(\",\")))\n",
    "    return ', '.join(unique_words)  # Join back into a string"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.344676Z",
     "start_time": "2025-02-13T14:37:21.525487Z"
    }
   },
   "source": [
    "# Clean openmoji_annotation column\n",
    "final_df[\"cleaned_annotations\"] = final_df[\"openmoji_annotation\"].progress_apply(clean_text)\n",
    "# Clean llm_tags\n",
    "final_df[\"cleaned_llm_tags\"] = final_df[\"llm_tags\"].progress_apply(clean_text)\n",
    "\n",
    "# List of columns to merge\n",
    "columns_to_merge = [\"cleaned_annotations\", \"openmoji_tags_1\", \"openmoji_tags_2\", \"cleaned_llm_tags\"]\n",
    "\n",
    "# Fill NaN with empty strings, then merge columns\n",
    "final_df[\"merged_tags\"] = final_df[columns_to_merge].fillna(\"\").agg(\n",
    "    lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 5496.13it/s]\n",
      "100%|██████████| 4298/4298 [00:00<00:00, 1706305.59it/s]\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.363992Z",
     "start_time": "2025-02-13T14:37:22.347167Z"
    }
   },
   "source": [
    "# Remove duplicates\n",
    "final_df[\"final_tags\"] = final_df[\"merged_tags\"].progress_apply(remove_duplicates)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 433959.67it/s]\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.380952Z",
     "start_time": "2025-02-13T14:37:22.365604Z"
    }
   },
   "source": [
    "# Limiting only 2 sentences because the content is too long with too many references to other emoji, which might be more confusing later for the model to learn.\n",
    "\n",
    "\"\"\"\n",
    "Reference: Chat-GPT-4o\n",
    "Prompt: My df_images has a emojipedia_description column. Only keep the first two sentences in the column and remove the rest.\n",
    "\"\"\"\n",
    "# Function to keep only the first two sentences\n",
    "def keep_first_two_sentences(description):\n",
    "    if pd.isna(description):  # Handle missing values (NaNs)\n",
    "        return description\n",
    "    sentences = re.split(r'(?<=[.!?]) +', description.strip())  # Split by sentence-ending punctuation (., !, ?)\n",
    "    return ' '.join(sentences[:2])  # Return only the first two sentences\n",
    "\n",
    "# Apply the function to the 'llm_description' column\n",
    "final_df['emojipedia_description'] = final_df['emojipedia_description'].progress_apply(keep_first_two_sentences)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 436249.03it/s]\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.387114Z",
     "start_time": "2025-02-13T14:37:22.381601Z"
    }
   },
   "source": [
    "final_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \\\n",
       "0                        NaN                    NaN      NaN             NaN   \n",
       "1                        NaN                    NaN      NaN             NaN   \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN   \n",
       "3                        NaN                    NaN      NaN             NaN   \n",
       "4                        NaN                    NaN      NaN             NaN   \n",
       "\n",
       "  cleaned_annotations cleaned_llm_tags  \\\n",
       "0           keycap, #                    \n",
       "1           keycap, *                    \n",
       "2         hyphenminus                    \n",
       "3           keycap, 0                    \n",
       "4           keycap, 1                    \n",
       "\n",
       "                              merged_tags  \\\n",
       "0                       keycap, #, keycap   \n",
       "1                       keycap, *, keycap   \n",
       "2  hyphenminus, hyphen, minus, dash, line   \n",
       "3                       keycap, 0, keycap   \n",
       "4                       keycap, 1, keycap   \n",
       "\n",
       "                               final_tags  \n",
       "0                               #, keycap  \n",
       "1                               *, keycap  \n",
       "2  dash, hyphen, hyphenminus, line, minus  \n",
       "3                               0, keycap  \n",
       "4                               1, keycap  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, #</td>\n",
       "      <td></td>\n",
       "      <td>keycap, #, keycap</td>\n",
       "      <td>#, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, *</td>\n",
       "      <td></td>\n",
       "      <td>keycap, *, keycap</td>\n",
       "      <td>*, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphenminus</td>\n",
       "      <td></td>\n",
       "      <td>hyphenminus, hyphen, minus, dash, line</td>\n",
       "      <td>dash, hyphen, hyphenminus, line, minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 0</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 0, keycap</td>\n",
       "      <td>0, keycap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 1</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 1, keycap</td>\n",
       "      <td>1, keycap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.394916Z",
     "start_time": "2025-02-13T14:37:22.387864Z"
    }
   },
   "source": [
    "final_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   emoji                   4282 non-null   object\n",
      " 1   hexcode                 4298 non-null   object\n",
      " 2   openmoji_annotation     4282 non-null   object\n",
      " 3   openmoji_tags_1         1906 non-null   object\n",
      " 4   openmoji_tags_2         391 non-null    object\n",
      " 5   emojipedia_description  1885 non-null   object\n",
      " 6   llm_tags                2622 non-null   object\n",
      " 7   llm_description         2622 non-null   object\n",
      " 8   cleaned_annotations     4298 non-null   object\n",
      " 9   cleaned_llm_tags        4298 non-null   object\n",
      " 10  merged_tags             4298 non-null   object\n",
      " 11  final_tags              4298 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 403.1+ KB\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding using Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:22.401997Z",
     "start_time": "2025-02-13T14:37:22.396490Z"
    }
   },
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mac GPU (MPS)\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:37:24.300943Z",
     "start_time": "2025-02-13T14:37:22.405998Z"
    }
   },
   "source": [
    "# Load SBERT model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_model = sbert_model.to(device)\n",
    "\n",
    "# Ensure text columns are strings\n",
    "# final_df[\"emojipedia_description\"] = final_df[\"emojipedia_description\"].fillna(\"\").astype(str)\n",
    "# final_df[\"llm_description\"] = final_df[\"llm_description\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Return SBERT embedding for a given text.\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return np.zeros(384, dtype=np.float32)  # Return zero vector for missing values (SBERT output size = 384)\n",
    "    return sbert_model.encode(text).astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:48.778442Z",
     "start_time": "2025-02-13T14:37:24.303597Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Reference: https://sbert.net/\n",
    "\"\"\"\n",
    "\n",
    "# Apply SBERT embeddings to each columns\n",
    "print(\"Embedding final_tags...\")\n",
    "final_df[\"tags_embedding\"] = final_df[\"final_tags\"].progress_apply(embed_text)\n",
    "\n",
    "print(\"Embedding emojipedia_description...\")\n",
    "final_df[\"emojipedia_embedding\"] = final_df[\"emojipedia_description\"].progress_apply(embed_text)\n",
    "\n",
    "print(\"Embedding llm_description...\")\n",
    "final_df[\"llm_embedding\"] = final_df[\"llm_description\"].progress_apply(embed_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding final_tags...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:39<00:00, 108.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding emojipedia_description...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:16<00:00, 257.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding llm_description...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:28<00:00, 151.90it/s]\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:48.816781Z",
     "start_time": "2025-02-13T14:38:48.779838Z"
    }
   },
   "source": [
    "final_df[\"combined_embedding\"] = final_df.apply(\n",
    "    lambda row: np.concatenate([row[\"tags_embedding\"], row[\"emojipedia_embedding\"], row[\"llm_embedding\"]]), axis=1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:38:48.830471Z",
     "start_time": "2025-02-13T14:38:48.817359Z"
    }
   },
   "source": [
    "final_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \\\n",
       "0                        NaN                    NaN      NaN             NaN   \n",
       "1                        NaN                    NaN      NaN             NaN   \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN   \n",
       "3                        NaN                    NaN      NaN             NaN   \n",
       "4                        NaN                    NaN      NaN             NaN   \n",
       "\n",
       "  cleaned_annotations cleaned_llm_tags  \\\n",
       "0           keycap, #                    \n",
       "1           keycap, *                    \n",
       "2         hyphenminus                    \n",
       "3           keycap, 0                    \n",
       "4           keycap, 1                    \n",
       "\n",
       "                              merged_tags  \\\n",
       "0                       keycap, #, keycap   \n",
       "1                       keycap, *, keycap   \n",
       "2  hyphenminus, hyphen, minus, dash, line   \n",
       "3                       keycap, 0, keycap   \n",
       "4                       keycap, 1, keycap   \n",
       "\n",
       "                               final_tags  \\\n",
       "0                               #, keycap   \n",
       "1                               *, keycap   \n",
       "2  dash, hyphen, hyphenminus, line, minus   \n",
       "3                               0, keycap   \n",
       "4                               1, keycap   \n",
       "\n",
       "                                      tags_embedding  \\\n",
       "0  [0.02519471, -0.04989285, 0.04940779, -0.01256...   \n",
       "1  [0.030324753, -0.047731012, 0.04585727, -0.008...   \n",
       "2  [-0.024587138, 0.10079276, 0.011220697, -0.040...   \n",
       "3  [0.043693572, -0.01632516, -0.030014936, 0.029...   \n",
       "4  [0.022134297, -0.07334993, -0.0056481804, -0.0...   \n",
       "\n",
       "                                emojipedia_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                       llm_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  combined_embedding  \n",
       "0  [0.02519471, -0.04989285, 0.04940779, -0.01256...  \n",
       "1  [0.030324753, -0.047731012, 0.04585727, -0.008...  \n",
       "2  [-0.024587138, 0.10079276, 0.011220697, -0.040...  \n",
       "3  [0.043693572, -0.01632516, -0.030014936, 0.029...  \n",
       "4  [0.022134297, -0.07334993, -0.0056481804, -0.0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>tags_embedding</th>\n",
       "      <th>emojipedia_embedding</th>\n",
       "      <th>llm_embedding</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, #</td>\n",
       "      <td></td>\n",
       "      <td>keycap, #, keycap</td>\n",
       "      <td>#, keycap</td>\n",
       "      <td>[0.02519471, -0.04989285, 0.04940779, -0.01256...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.02519471, -0.04989285, 0.04940779, -0.01256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, *</td>\n",
       "      <td></td>\n",
       "      <td>keycap, *, keycap</td>\n",
       "      <td>*, keycap</td>\n",
       "      <td>[0.030324753, -0.047731012, 0.04585727, -0.008...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.030324753, -0.047731012, 0.04585727, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphenminus</td>\n",
       "      <td></td>\n",
       "      <td>hyphenminus, hyphen, minus, dash, line</td>\n",
       "      <td>dash, hyphen, hyphenminus, line, minus</td>\n",
       "      <td>[-0.024587138, 0.10079276, 0.011220697, -0.040...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-0.024587138, 0.10079276, 0.011220697, -0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 0</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 0, keycap</td>\n",
       "      <td>0, keycap</td>\n",
       "      <td>[0.043693572, -0.01632516, -0.030014936, 0.029...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.043693572, -0.01632516, -0.030014936, 0.029...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>keycap, 1</td>\n",
       "      <td></td>\n",
       "      <td>keycap, 1, keycap</td>\n",
       "      <td>1, keycap</td>\n",
       "      <td>[0.022134297, -0.07334993, -0.0056481804, -0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.022134297, -0.07334993, -0.0056481804, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:14.420893Z",
     "start_time": "2025-02-13T14:38:48.831122Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"OpenMojiEmoji\", \"TwitterEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(final_df.iterrows(), total=len(final_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|██████████| 4298/4298 [00:25<00:00, 168.06it/s]\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:14.428613Z",
     "start_time": "2025-02-13T14:39:14.422175Z"
    }
   },
   "source": "expanded_df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12510 entries, 0 to 12509\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             12510 non-null  object\n",
      " 1   combined_embedding  12510 non-null  object\n",
      " 2   image_path          12510 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 293.3+ KB\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:39:14.700473Z",
     "start_time": "2025-02-13T14:39:14.429487Z"
    }
   },
   "cell_type": "code",
   "source": "expanded_df[['combined_embedding', 'image_path']].to_parquet('../data/processed_emoji_dataset.parquet', index=False)",
   "outputs": [],
   "execution_count": 98
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
