{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU (CUDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5034/5034 [00:00<00:00, 983104.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n",
      "hexcode\n",
      "1f3cc-2640               4\n",
      "1f575-2640               4\n",
      "1f6b6-1f3fe-2642-27a1    4\n",
      "1f3c3-2640-27a1          4\n",
      "1f3c3-1f3ff-2640-27a1    4\n",
      "                        ..\n",
      "261d                     2\n",
      "267e                     2\n",
      "2139                     2\n",
      "26f8                     2\n",
      "1f470-1f3fb-2640         2\n",
      "Name: count, Length: 1160, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      "dtypes: float64(1), object(19)\n",
      "memory usage: 375.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2404/2404 [00:00<00:00, 2305237.04it/s]\n",
      "100%|██████████| 2404/2404 [00:00<00:00, 456022.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      " 20  cleaned_llm_tags       2404 non-null   object \n",
      " 21  merged_tags            2404 non-null   object \n",
      " 22  final_tags             2404 non-null   object \n",
      " 23  merged_description     2404 non-null   object \n",
      "dtypes: float64(1), object(23)\n",
      "memory usage: 450.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2712 entries, 0 to 2711\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2712 non-null   object \n",
      " 1   hexcode                2712 non-null   object \n",
      " 2   group                  2712 non-null   object \n",
      " 3   subgroups              2712 non-null   object \n",
      " 4   annotation             2712 non-null   object \n",
      " 5   tags_x                 837 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2712 non-null   object \n",
      " 8   openmoji_date          2712 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2712 non-null   object \n",
      " 14  order                  2712 non-null   float64\n",
      " 15  character              1741 non-null   object \n",
      " 16  unicode_y              1741 non-null   object \n",
      " 17  short description      1741 non-null   object \n",
      " 18  tags_y                 1741 non-null   object \n",
      " 19  LLM description        1741 non-null   object \n",
      " 20  cleaned_llm_tags       2712 non-null   object \n",
      " 21  merged_tags            2712 non-null   object \n",
      " 22  final_tags             2712 non-null   object \n",
      " 23  merged_description     2712 non-null   object \n",
      "dtypes: float64(1), object(23)\n",
      "memory usage: 508.6+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2712/2712 [00:26<00:00, 103.43it/s]\n",
      "Processing Hexcodes: 100%|██████████| 2712/2712 [00:09<00:00, 293.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2712 entries, 0 to 2711\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             2712 non-null   object\n",
      " 1   combined_embedding  2712 non-null   object\n",
      " 2   image_path          2712 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 63.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')\n",
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)\n",
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.lower()\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.lower()\n",
    "# Selecting specific groups of emojis to train the model\n",
    "openmoji_df = openmoji_df[openmoji_df[\"group\"].isin([\"smileys-emotion\", \"people-body\"])]\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"subgroups\"].isin([\"person-symbol\", \"emotion\"])]\n",
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)\n",
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)\n",
    "# Removing duplicates\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]\n",
    "# Merge the dataframes on 'hexcode' with left join on openmoji_df\n",
    "merged_df = openmoji_df.merge(llm_df, on='hexcode', how='left')\n",
    "merged_df.info()\n",
    "## Handling Tags and Descriptions\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "    # Keep only letters, numbers, spaces, * and #\n",
    "    text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ', '.join(tokens)\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = list(dict.fromkeys(words))\n",
    "    return ', '.join(unique_words)  # Join back into a string\n",
    "# Clean openmoji_annotation column\n",
    "# Clean llm_tags\n",
    "merged_df[\"cleaned_llm_tags\"] = merged_df[\"tags_y\"].progress_apply(clean_text)\n",
    "\n",
    "# List of columns to merge (All tags)\n",
    "columns_to_merge = [\"tags_x\", \"cleaned_llm_tags\"]\n",
    "\n",
    "# Fill NaN with empty strings, then merge columns\n",
    "merged_df[\"merged_tags\"] = merged_df[columns_to_merge].fillna(\"\").agg(\n",
    "    lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    ")\n",
    "# Remove duplicates\n",
    "merged_df[\"final_tags\"] = merged_df[\"merged_tags\"].progress_apply(remove_duplicates)\n",
    "# Function to handle concatenation with empty strings and NaN values\n",
    "def merge_descriptions(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['annotation']):\n",
    "        annotation = row['annotation'].strip()\n",
    "        if annotation:  # Ensure it's not empty after stripping\n",
    "            parts.append(annotation)\n",
    "    if pd.notna(row['LLM description']):\n",
    "        description = row['LLM description'].strip()\n",
    "        if description:\n",
    "            parts.append(description)\n",
    "    if pd.notna(row['final_tags']):\n",
    "        tags = row['final_tags'].strip()\n",
    "        if tags:\n",
    "            parts.append(f\"Tags: {tags}\")  # Ensure the \"Tags: \" prefix is only added if valid\n",
    "\n",
    "    return \". \".join(parts) if parts else None  # Return None if no valid parts\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df['merged_description'] = merged_df.apply(merge_descriptions, axis=1)\n",
    "merged_df.info()\n",
    "# Duplicate smiley emoji records so that the model has enough to learn from\n",
    "\n",
    "# Filter rows with group \"smileys-emotion\"\n",
    "smileys_df = merged_df[merged_df['group'] == 'smileys-emotion']\n",
    "\n",
    "# Duplicate these rows 3 times\n",
    "duplicated_smileys_df = pd.concat([smileys_df] * 2, ignore_index=True)\n",
    "\n",
    "# Append back to the original DataFrame\n",
    "merged_df = pd.concat([merged_df, duplicated_smileys_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset to mix the records\n",
    "merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "merged_df.info()\n",
    "## Embedding Emoji Condition\n",
    "\"\"\"\n",
    "Reference: https://huggingface.co/docs/transformers/model_doc/clip\n",
    "\"\"\"\n",
    "\n",
    "# Load CLIP's tokenizer and text model.\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()\n",
    "\"\"\"\n",
    "Reference: ChatGPT o3-mini-high\n",
    "Prompt: Write a code to embed my description column in my df using CLIP-vit-base-patch32. Use Mean Pooling + L2 Normalization method to generate embeddings.\n",
    "\n",
    "Reason: We're using Mean Pooling + L2 Normalization to retain fine-grained meanings related to gender, skin tone, emotions, and objects. We're also using L2 Normalization because they have a consistent scale, reducing variance in GAN training.\n",
    "\"\"\"\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean pool the token embeddings.\"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state  # (batch_size, sequence_length, hidden_dim)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, dim=1) / torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        # Adjust the zero vector size to match CLIP's output dimension (512 for clip-vit-base-patch32)\n",
    "        return np.zeros(512, dtype=np.float32)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = clip_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=77)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        output = clip_model(**inputs)\n",
    "    \n",
    "    # Pool the token embeddings (mean pooling)\n",
    "    pooled_embedding = mean_pooling(output, inputs[\"attention_mask\"])\n",
    "    \n",
    "    # Optionally, you might want to L2 normalize the pooled embedding:\n",
    "    pooled_embedding = torch.nn.functional.normalize(pooled_embedding, p=2, dim=-1)\n",
    "    \n",
    "    return pooled_embedding.squeeze().cpu().numpy().astype(np.float32)\n",
    "# Apply CLIP embedding to your dataset\n",
    "merged_df[\"combined_embedding\"] = merged_df[\"merged_description\"].progress_apply(embed_text)\n",
    "merged_df.head()\n",
    "## Linking Images\n",
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "# brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"TwitterEmoji\"]\n",
    "brands = [\"OpenMojiEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)\n",
    "expanded_df.info()\n",
    "output_file = '../data/processed_emoji_dataset.parquet'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "expanded_df[['combined_embedding', 'image_path']].to_parquet(output_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
