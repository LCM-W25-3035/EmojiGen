{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:28.810879Z",
     "start_time": "2025-04-06T12:44:18.841361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU (CUDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.089154Z",
     "start_time": "2025-04-06T12:44:28.818239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')\n",
    "emojipedia_df = pd.read_csv('../data/emojipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.160337Z",
     "start_time": "2025-04-06T12:44:29.091047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5034/5034 [00:00<00:00, 1252246.39it/s]\n",
      "100%|██████████| 1885/1885 [00:00<00:00, 1288714.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['Codepoints Hex'].progress_apply(unicode_to_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.189656Z",
     "start_time": "2025-04-06T12:44:29.165125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "openmoji_df['skintone_base_hexcode'] = openmoji_df['skintone_base_hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['skintone_base_hexcode'] = openmoji_df['skintone_base_hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-200D', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.218695Z",
     "start_time": "2025-04-06T12:44:29.211334Z"
    }
   },
   "outputs": [],
   "source": [
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.lower()\n",
    "openmoji_df['skintone_base_hexcode'] = openmoji_df['skintone_base_hexcode'].str.lower()\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.lower()\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.233291Z",
     "start_time": "2025-04-06T12:44:29.220180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping symbols, extras-openmoji, extras-unicode and flags categories\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"group\"].isin([\"symbols\", \"extras-openmoji\", \"extras-unicode\", \"flags\"])]\n",
    "\n",
    "# Dropping records of skin colors and hair types\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"hexcode\"].isin([\"1f3fb\", \"1f3fc\", \"1f3fd\", \"1f3fe\", \"1f3ff\", \"1f9b0\", \"1f9b1\", \"1f9b3\", \"1f9b2\"])]\n",
    "\n",
    "# Drop all records with multiple skintone combinations\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"skintone_combination\"].isin([\"multiple\"])]\n",
    "\n",
    "# Setting skintone to 0 where no skintone is specified\n",
    "openmoji_df['skintone'] = openmoji_df['skintone'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.242468Z",
     "start_time": "2025-04-06T12:44:29.235605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.256560Z",
     "start_time": "2025-04-06T12:44:29.243962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1f3cc-2640               4\n",
      "1f575-2640               4\n",
      "1f6b6-1f3fe-2642-27a1    4\n",
      "1f3c3-2640-27a1          4\n",
      "1f3c3-1f3ff-2640-27a1    4\n",
      "                        ..\n",
      "261d                     2\n",
      "267e                     2\n",
      "2139                     2\n",
      "26f8                     2\n",
      "1f470-1f3fb-2640         2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.264079Z",
     "start_time": "2025-04-06T12:44:29.257760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = emojipedia_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.269929Z",
     "start_time": "2025-04-06T12:44:29.265047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.290893Z",
     "start_time": "2025-04-06T12:44:29.272653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'hexcode' with left join on openmoji_df\n",
    "merged_df = openmoji_df.merge(llm_df, on='hexcode', how='left')\n",
    "merged_df = merged_df.merge(emojipedia_df, on='hexcode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.313982Z",
     "start_time": "2025-04-06T12:44:29.292348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3021 entries, 0 to 3020\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  3021 non-null   object \n",
      " 1   hexcode                3021 non-null   object \n",
      " 2   group                  3021 non-null   object \n",
      " 3   subgroups              3021 non-null   object \n",
      " 4   annotation             3021 non-null   object \n",
      " 5   tags_x                 1406 non-null   object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        3021 non-null   object \n",
      " 8   openmoji_date          3021 non-null   object \n",
      " 9   skintone               3021 non-null   object \n",
      " 10  skintone_combination   1938 non-null   object \n",
      " 11  skintone_base_emoji    1938 non-null   object \n",
      " 12  skintone_base_hexcode  1938 non-null   object \n",
      " 13  unicode_x              3021 non-null   object \n",
      " 14  order                  3021 non-null   float64\n",
      " 15  character              2106 non-null   object \n",
      " 16  unicode_y              2106 non-null   object \n",
      " 17  short description      2106 non-null   object \n",
      " 18  tags_y                 2106 non-null   object \n",
      " 19  LLM description        2106 non-null   object \n",
      " 20  Group                  1392 non-null   object \n",
      " 21  Subgroup               1392 non-null   object \n",
      " 22  Emoji                  1392 non-null   object \n",
      " 23  Title                  1392 non-null   object \n",
      " 24  DescribedBy            1392 non-null   object \n",
      " 25  URL                    1392 non-null   object \n",
      " 26  Description            1392 non-null   object \n",
      " 27  Codepoints Hex         1392 non-null   object \n",
      "dtypes: float64(1), object(27)\n",
      "memory usage: 661.0+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.323983Z",
     "start_time": "2025-04-06T12:44:29.315202Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_first_sentence(text):\n",
    "    \"\"\"\n",
    "    Extracts the first sentence from a given text.\n",
    "    A sentence ends with '.', '?', or '!' followed by space or end of string.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Return as-is if not a string\n",
    "    \n",
    "    match = re.match(r'(.+?[.!?])(\\s|$)', text.strip())\n",
    "    return match.group(1) if match else text\n",
    "\n",
    "merged_df[\"Description\"] = merged_df[\"Description\"].apply(get_first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.334234Z",
     "start_time": "2025-04-06T12:44:29.331469Z"
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Normalize and remove unwanted characters.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\"():;\\-\\n]+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.339974Z",
     "start_time": "2025-04-06T12:44:29.336340Z"
    }
   },
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "#         return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "#     text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "#     # Keep only letters, numbers, spaces, * and #\n",
    "#     text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text)\n",
    "#     # Remove stop words\n",
    "#     tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "#     return ', '.join(tokens)\n",
    "# \n",
    "# def remove_duplicates(text):\n",
    "#     words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "#     unique_words = list(dict.fromkeys(words))\n",
    "#     return ', '.join(unique_words)  # Join back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.362335Z",
     "start_time": "2025-04-06T12:44:29.343607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning annotation, LLM description and openmoji_description\n",
    "merged_df[\"annotation\"] = merged_df[\"annotation\"].apply(clean_text)\n",
    "merged_df[\"LLM description\"] = merged_df[\"LLM description\"].apply(clean_text)\n",
    "merged_df[\"Description\"] = merged_df[\"Description\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.383808Z",
     "start_time": "2025-04-06T12:44:29.364159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a mapping from hexcode to Description (only non-null ones)\n",
    "hexcode_to_description = merged_df[merged_df['Description'].notnull()] \\\n",
    "    .set_index('hexcode')['Description'].to_dict()\n",
    "\n",
    "# Fill missing Descriptions based on skintone_base_hexcode\n",
    "merged_df['Description'] = merged_df.apply(\n",
    "    lambda row: hexcode_to_description.get(row['skintone_base_hexcode'], row['Description'])\n",
    "    if pd.isnull(row['Description']) else row['Description'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.404203Z",
     "start_time": "2025-04-06T12:44:29.384613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge annotation with a description\n",
    "# Use LLM description if it exists, otherwise use Description\n",
    "def generate_prompt(row):\n",
    "    # Start with annotation (always exists)\n",
    "    prompt = row['annotation']\n",
    "\n",
    "    # Try LLM description, then Description\n",
    "    extra = row['LLM description'] if pd.notnull(row['LLM description']) else row['Description']\n",
    "\n",
    "    # If there's extra content, append with a space\n",
    "    if pd.notnull(extra):\n",
    "        prompt += '. ' + extra\n",
    "\n",
    "    return prompt\n",
    "\n",
    "merged_df['prompt'] = merged_df.apply(generate_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.409458Z",
     "start_time": "2025-04-06T12:44:29.406625Z"
    }
   },
   "outputs": [],
   "source": [
    "# merged_df['prompt'] = merged_df['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.415787Z",
     "start_time": "2025-04-06T12:44:29.411692Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Clean openmoji_annotation column\n",
    "# # Clean llm_tags\n",
    "# merged_df[\"cleaned_llm_tags\"] = merged_df[\"tags_y\"].progress_apply(clean_text)\n",
    "# \n",
    "# # List of columns to merge (All tags)\n",
    "# columns_to_merge = [\"tags_x\", \"cleaned_llm_tags\"]\n",
    "# \n",
    "# # Fill NaN with empty strings, then merge columns\n",
    "# merged_df[\"merged_tags\"] = merged_df[columns_to_merge].fillna(\"\").agg(\n",
    "#     lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.422084Z",
     "start_time": "2025-04-06T12:44:29.419251Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Remove duplicates\n",
    "# merged_df[\"final_tags\"] = merged_df[\"merged_tags\"].progress_apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.424722Z",
     "start_time": "2025-04-06T12:44:29.422988Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Function to handle concatenation with empty strings and NaN values\n",
    "# def merge_descriptions(row):\n",
    "#     parts = []\n",
    "#     if pd.notna(row['annotation']):\n",
    "#         annotation = row['annotation'].strip()\n",
    "#         if annotation:  # Ensure it's not empty after stripping\n",
    "#             parts.append(annotation)\n",
    "#     if pd.notna(row['LLM description']):\n",
    "#         description = row['LLM description'].strip()\n",
    "#         if description:\n",
    "#             parts.append(description)\n",
    "#     if pd.notna(row['final_tags']):\n",
    "#         tags = row['final_tags'].strip()\n",
    "#         if tags:\n",
    "#             parts.append(f\"Tags: {tags}\")  # Ensure the \"Tags: \" prefix is only added if valid\n",
    "# \n",
    "#     return \". \".join(parts) if parts else None  # Return None if no valid parts\n",
    "# \n",
    "# # Apply the function to each row\n",
    "# merged_df['merged_description'] = merged_df.apply(merge_descriptions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.428229Z",
     "start_time": "2025-04-06T12:44:29.426009Z"
    }
   },
   "outputs": [],
   "source": [
    "# merged_df.info()\n",
    "# merged_df.to_csv('../data/test_emoji_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.430251Z",
     "start_time": "2025-04-06T12:44:29.428774Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Duplicate smiley emoji records so that the model has enough to learn from\n",
    "# \n",
    "# # Filter rows with group \"smileys-emotion\"\n",
    "# smileys_df = merged_df[merged_df['group'] == 'smileys-emotion']\n",
    "# \n",
    "# # Duplicate these rows 3 times\n",
    "# duplicated_smileys_df = pd.concat([smileys_df] * 2, ignore_index=True)\n",
    "# \n",
    "# # Append back to the original DataFrame\n",
    "# merged_df = pd.concat([merged_df, duplicated_smileys_df], ignore_index=True)\n",
    "# \n",
    "# # Shuffle the dataset to mix the records\n",
    "# merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:29.436769Z",
     "start_time": "2025-04-06T12:44:29.430831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3021 entries, 0 to 3020\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  3021 non-null   object \n",
      " 1   hexcode                3021 non-null   object \n",
      " 2   group                  3021 non-null   object \n",
      " 3   subgroups              3021 non-null   object \n",
      " 4   annotation             3021 non-null   object \n",
      " 5   tags_x                 1406 non-null   object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        3021 non-null   object \n",
      " 8   openmoji_date          3021 non-null   object \n",
      " 9   skintone               3021 non-null   object \n",
      " 10  skintone_combination   1938 non-null   object \n",
      " 11  skintone_base_emoji    1938 non-null   object \n",
      " 12  skintone_base_hexcode  1938 non-null   object \n",
      " 13  unicode_x              3021 non-null   object \n",
      " 14  order                  3021 non-null   float64\n",
      " 15  character              2106 non-null   object \n",
      " 16  unicode_y              2106 non-null   object \n",
      " 17  short description      2106 non-null   object \n",
      " 18  tags_y                 2106 non-null   object \n",
      " 19  LLM description        2106 non-null   object \n",
      " 20  Group                  1392 non-null   object \n",
      " 21  Subgroup               1392 non-null   object \n",
      " 22  Emoji                  1392 non-null   object \n",
      " 23  Title                  1392 non-null   object \n",
      " 24  DescribedBy            1392 non-null   object \n",
      " 25  URL                    1392 non-null   object \n",
      " 26  Description            3007 non-null   object \n",
      " 27  Codepoints Hex         1392 non-null   object \n",
      " 28  prompt                 3021 non-null   object \n",
      "dtypes: float64(1), object(28)\n",
      "memory usage: 684.6+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Emoji Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:31.102122Z",
     "start_time": "2025-04-06T12:44:29.437288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPSdpaAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference: https://huggingface.co/docs/transformers/model_doc/clip\n",
    "\"\"\"\n",
    "\n",
    "# Load CLIP's tokenizer and text model.\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:44:31.112987Z",
     "start_time": "2025-04-06T12:44:31.104494Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference: ChatGPT o3-mini-high\n",
    "Prompt: Write a code to embed my description column in my df using CLIP-vit-base-patch32. Use Mean Pooling + L2 Normalization method to generate embeddings.\n",
    "\n",
    "Reason: We're using Mean Pooling + L2 Normalization to retain fine-grained meanings related to gender, skin tone, emotions, and objects. We're also using L2 Normalization because they have a consistent scale, reducing variance in GAN training.\n",
    "\"\"\"\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean pool the token embeddings.\"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state  # (batch_size, sequence_length, hidden_dim)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, dim=1) / torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        # Adjust the zero vector size to match CLIP's output dimension (512 for clip-vit-base-patch32)\n",
    "        return np.zeros(512, dtype=np.float32)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = clip_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=77)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        output = clip_model(**inputs)\n",
    "\n",
    "    # Pool the token embeddings (mean pooling)\n",
    "    pooled_embedding = mean_pooling(output, inputs[\"attention_mask\"])\n",
    "\n",
    "    # Optionally, you might want to L2 normalize the pooled embedding:\n",
    "    pooled_embedding = torch.nn.functional.normalize(pooled_embedding, p=2, dim=-1)\n",
    "\n",
    "    return pooled_embedding.squeeze().cpu().numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:43.350380Z",
     "start_time": "2025-04-06T12:44:31.114675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3021/3021 [00:23<00:00, 127.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply CLIP embedding to your dataset\n",
    "merged_df[\"combined_embedding\"] = merged_df[\"prompt\"].progress_apply(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:43.378844Z",
     "start_time": "2025-04-06T12:45:43.355146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>Group</th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Title</th>\n",
       "      <th>DescribedBy</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Codepoints Hex</th>\n",
       "      <th>prompt</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>😀</td>\n",
       "      <td>1f600</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>face, grin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>smiley</td>\n",
       "      <td>Smiling &amp; Affectionate</td>\n",
       "      <td>😀</td>\n",
       "      <td>Grinning Face</td>\n",
       "      <td>grinning-face</td>\n",
       "      <td>/grinning-face</td>\n",
       "      <td>A yellow face with simple, open eyes and a bro...</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>grinning face. This emoji represents a smiling...</td>\n",
       "      <td>[-0.009248996, -0.047418017, -0.00524062, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>😃</td>\n",
       "      <td>1f603</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "      <td>face, mouth, open, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>smiley</td>\n",
       "      <td>Smiling &amp; Affectionate</td>\n",
       "      <td>😃</td>\n",
       "      <td>Grinning Face with Big Eyes</td>\n",
       "      <td>grinning-face-with-big-eyes</td>\n",
       "      <td>/grinning-face-with-big-eyes</td>\n",
       "      <td>A yellow face with smiling eyes and a broad, o...</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>grinning face with big eyes. This emoji repres...</td>\n",
       "      <td>[0.01590147, -0.03315458, -0.010774368, 0.0427...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>😄</td>\n",
       "      <td>1f604</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>eye, face, mouth, open, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>smiley</td>\n",
       "      <td>Smiling &amp; Affectionate</td>\n",
       "      <td>😄</td>\n",
       "      <td>Grinning Face with Smiling Eyes</td>\n",
       "      <td>grinning-face-with-smiling-eyes</td>\n",
       "      <td>/grinning-face-with-smiling-eyes</td>\n",
       "      <td>A yellow face with smiling eyes and a broad, o...</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>grinning face with smiling eyes. This emoji re...</td>\n",
       "      <td>[-0.00059326674, -0.04860326, -0.004713649, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>😁</td>\n",
       "      <td>1f601</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "      <td>eye, face, grin, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>smiley</td>\n",
       "      <td>Smiling &amp; Affectionate</td>\n",
       "      <td>😁</td>\n",
       "      <td>Beaming Face with Smiling Eyes</td>\n",
       "      <td>beaming-face-with-smiling-eyes</td>\n",
       "      <td>/beaming-face-with-smiling-eyes</td>\n",
       "      <td>A yellow face with smiling eyes and full-tooth...</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>beaming face with smiling eyes. This emoji rep...</td>\n",
       "      <td>[-0.00021087428, -0.035330784, -0.004500972, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>😆</td>\n",
       "      <td>1f606</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning squinting face</td>\n",
       "      <td>face, laugh, mouth, satisfied, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>smiley</td>\n",
       "      <td>Smiling &amp; Affectionate</td>\n",
       "      <td>😆</td>\n",
       "      <td>Grinning Squinting Face</td>\n",
       "      <td>grinning-squinting-face</td>\n",
       "      <td>/grinning-squinting-face</td>\n",
       "      <td>A yellow face with a broad, open smile and scr...</td>\n",
       "      <td>U+1F606</td>\n",
       "      <td>grinning squinting face. This emoji represents...</td>\n",
       "      <td>[0.0041811448, -0.039693132, -0.010858626, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji hexcode            group     subgroups  \\\n",
       "0     😀   1f600  smileys-emotion  face-smiling   \n",
       "1     😃   1f603  smileys-emotion  face-smiling   \n",
       "2     😄   1f604  smileys-emotion  face-smiling   \n",
       "3     😁   1f601  smileys-emotion  face-smiling   \n",
       "4     😆   1f606  smileys-emotion  face-smiling   \n",
       "\n",
       "                        annotation                                tags_x  \\\n",
       "0                    grinning face                            face, grin   \n",
       "1      grinning face with big eyes              face, mouth, open, smile   \n",
       "2  grinning face with smiling eyes         eye, face, mouth, open, smile   \n",
       "3   beaming face with smiling eyes                eye, face, grin, smile   \n",
       "4          grinning squinting face  face, laugh, mouth, satisfied, smile   \n",
       "\n",
       "  openmoji_tags openmoji_author openmoji_date skintone  ...   Group  \\\n",
       "0           NaN     Emily Jäger    2018-04-18        0  ...  smiley   \n",
       "1           NaN     Emily Jäger    2018-04-18        0  ...  smiley   \n",
       "2           NaN     Emily Jäger    2018-04-18        0  ...  smiley   \n",
       "3           NaN     Emily Jäger    2018-04-18        0  ...  smiley   \n",
       "4           NaN     Emily Jäger    2018-04-18        0  ...  smiley   \n",
       "\n",
       "                 Subgroup Emoji                            Title  \\\n",
       "0  Smiling & Affectionate     😀                    Grinning Face   \n",
       "1  Smiling & Affectionate     😃      Grinning Face with Big Eyes   \n",
       "2  Smiling & Affectionate     😄  Grinning Face with Smiling Eyes   \n",
       "3  Smiling & Affectionate     😁   Beaming Face with Smiling Eyes   \n",
       "4  Smiling & Affectionate     😆          Grinning Squinting Face   \n",
       "\n",
       "                       DescribedBy                               URL  \\\n",
       "0                    grinning-face                    /grinning-face   \n",
       "1      grinning-face-with-big-eyes      /grinning-face-with-big-eyes   \n",
       "2  grinning-face-with-smiling-eyes  /grinning-face-with-smiling-eyes   \n",
       "3   beaming-face-with-smiling-eyes   /beaming-face-with-smiling-eyes   \n",
       "4          grinning-squinting-face          /grinning-squinting-face   \n",
       "\n",
       "                                         Description Codepoints Hex  \\\n",
       "0  A yellow face with simple, open eyes and a bro...        U+1F600   \n",
       "1  A yellow face with smiling eyes and a broad, o...        U+1F603   \n",
       "2  A yellow face with smiling eyes and a broad, o...        U+1F604   \n",
       "3  A yellow face with smiling eyes and full-tooth...        U+1F601   \n",
       "4  A yellow face with a broad, open smile and scr...        U+1F606   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  grinning face. This emoji represents a smiling...   \n",
       "1  grinning face with big eyes. This emoji repres...   \n",
       "2  grinning face with smiling eyes. This emoji re...   \n",
       "3  beaming face with smiling eyes. This emoji rep...   \n",
       "4  grinning squinting face. This emoji represents...   \n",
       "\n",
       "                                  combined_embedding  \n",
       "0  [-0.009248996, -0.047418017, -0.00524062, 0.03...  \n",
       "1  [0.01590147, -0.03315458, -0.010774368, 0.0427...  \n",
       "2  [-0.00059326674, -0.04860326, -0.004713649, 0....  \n",
       "3  [-0.00021087428, -0.035330784, -0.004500972, 0...  \n",
       "4  [0.0041811448, -0.039693132, -0.010858626, 0.0...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:49.119240Z",
     "start_time": "2025-04-06T12:45:43.380904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|██████████| 3021/3021 [00:07<00:00, 402.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "# brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"TwitterEmoji\"]\n",
    "brands = [\"GoogleEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "    prompt = row[\"prompt\"]\n",
    "    skintone = row[\"skintone\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"prompt\": prompt, \"skintone\":skintone, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"prompt\": prompt, \"skintone\":skintone, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "# expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:49.131749Z",
     "start_time": "2025-04-06T12:45:49.121637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3021 entries, 0 to 3020\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             3021 non-null   object\n",
      " 1   prompt              3021 non-null   object\n",
      " 2   skintone            3021 non-null   object\n",
      " 3   combined_embedding  3021 non-null   object\n",
      " 4   image_path          3021 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 118.1+ KB\n"
     ]
    }
   ],
   "source": [
    "expanded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:49.137548Z",
     "start_time": "2025-04-06T12:45:49.133177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try converting skintone column to numeric (if possible)\n",
    "expanded_df['skintone'] = pd.to_numeric(expanded_df['skintone'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:49.203927Z",
     "start_time": "2025-04-06T12:45:49.138859Z"
    }
   },
   "outputs": [],
   "source": [
    "output_file = '../data/processed_emoji_dataset.parquet'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "expanded_df.to_parquet(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T12:45:49.206513Z",
     "start_time": "2025-04-06T12:45:49.204826Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
