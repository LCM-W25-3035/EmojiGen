{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.095299Z",
     "start_time": "2025-02-16T06:41:40.667090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jyoti Prakash\n",
      "[nltk_data]     Uprety\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.263769Z",
     "start_time": "2025-02-16T06:41:41.097445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "emojipedia_df = pd.read_csv('../data/emojipedia.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.282839Z",
     "start_time": "2025-02-16T06:41:41.264910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1885/1885 [00:00<00:00, 772397.72it/s]\n",
      "100%|██████████| 5034/5034 [00:00<00:00, 1179230.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "emojipedia_df['hexcode'] = emojipedia_df['Codepoints Hex'].progress_apply(unicode_to_hex)\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.296923Z",
     "start_time": "2025-02-16T06:41:41.284521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "emojipedia_df['hexcode'] = emojipedia_df['hexcode'].str.replace('-200D', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.313053Z",
     "start_time": "2025-02-16T06:41:41.297491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3F3    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.321711Z",
     "start_time": "2025-02-16T06:41:41.315779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1F3CC-2640               4\n",
      "1F575-2640               4\n",
      "1F6B6-1F3FE-2642-27A1    4\n",
      "1F3C3-2640-27A1          4\n",
      "1F3C3-1F3FF-2640-27A1    4\n",
      "                        ..\n",
      "261D                     2\n",
      "267E                     2\n",
      "2139                     2\n",
      "26F8                     2\n",
      "1F470-1F3FB-2640         2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.326345Z",
     "start_time": "2025-02-16T06:41:41.322687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "duplicate_counts = emojipedia_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.333964Z",
     "start_time": "2025-02-16T06:41:41.327138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "openmoji_df = openmoji_df[~openmoji_df.duplicated(subset=['hexcode'], keep=False)]\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.364169Z",
     "start_time": "2025-02-16T06:41:41.334790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'hexcode'\n",
    "merged_df = openmoji_df.merge(emojipedia_df, on='hexcode', how='outer')\n",
    "merged_df = merged_df.merge(llm_df, on='hexcode', how='outer')\n",
    "# Convert hexcode to lowercase\n",
    "merged_df['hexcode'] = merged_df['hexcode'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.378371Z",
     "start_time": "2025-02-16T06:41:41.366691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>Title</th>\n",
       "      <th>DescribedBy</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Codepoints Hex</th>\n",
       "      <th>character</th>\n",
       "      <th>unicode_y</th>\n",
       "      <th>short description</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>LLM description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>extras-unicode</td>\n",
       "      <td>symbol-other</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>Robert Winslow</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>symbols</td>\n",
       "      <td>keycap</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selina Lange</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode           group     subgroups    annotation  tags_x  \\\n",
       "0   #️⃣  0023-20e3         symbols        keycap     keycap: #  keycap   \n",
       "1   *️⃣  002a-20e3         symbols        keycap     keycap: *  keycap   \n",
       "2     -       002d  extras-unicode  symbol-other  hyphen-minus     NaN   \n",
       "3   0️⃣  0030-20e3         symbols        keycap     keycap: 0  keycap   \n",
       "4   1️⃣  0031-20e3         symbols        keycap     keycap: 1  keycap   \n",
       "\n",
       "               openmoji_tags openmoji_author openmoji_date skintone  ...  \\\n",
       "0                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "1                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "2  hyphen, minus, dash, line  Robert Winslow    2022-12-24      NaN  ...   \n",
       "3                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "4                        NaN    Selina Lange    2019-05-06      NaN  ...   \n",
       "\n",
       "  Title DescribedBy  URL Description  Codepoints Hex character unicode_y  \\\n",
       "0   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "1   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "2   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "3   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "4   NaN         NaN  NaN         NaN             NaN       NaN       NaN   \n",
       "\n",
       "  short description tags_y LLM description  \n",
       "0               NaN    NaN             NaN  \n",
       "1               NaN    NaN             NaN  \n",
       "2               NaN    NaN             NaN  \n",
       "3               NaN    NaN             NaN  \n",
       "4               NaN    NaN             NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.392163Z",
     "start_time": "2025-02-16T06:41:41.379663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  4282 non-null   object \n",
      " 1   hexcode                4298 non-null   object \n",
      " 2   group                  4282 non-null   object \n",
      " 3   subgroups              4282 non-null   object \n",
      " 4   annotation             4282 non-null   object \n",
      " 5   tags_x                 1906 non-null   object \n",
      " 6   openmoji_tags          391 non-null    object \n",
      " 7   openmoji_author        4282 non-null   object \n",
      " 8   openmoji_date          4282 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              3902 non-null   object \n",
      " 14  order                  3781 non-null   float64\n",
      " 15  Group                  1885 non-null   object \n",
      " 16  Subgroup               1885 non-null   object \n",
      " 17  Emoji                  1885 non-null   object \n",
      " 18  Title                  1885 non-null   object \n",
      " 19  DescribedBy            1885 non-null   object \n",
      " 20  URL                    1885 non-null   object \n",
      " 21  Description            1885 non-null   object \n",
      " 22  Codepoints Hex         1885 non-null   object \n",
      " 23  character              2622 non-null   object \n",
      " 24  unicode_y              2622 non-null   object \n",
      " 25  short description      2622 non-null   object \n",
      " 26  tags_y                 2622 non-null   object \n",
      " 27  LLM description        2622 non-null   object \n",
      "dtypes: float64(1), object(27)\n",
      "memory usage: 940.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.399626Z",
     "start_time": "2025-02-16T06:41:41.392809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select and rename required columns\n",
    "final_df = merged_df.copy()\n",
    "final_df = final_df[['emoji', 'hexcode', 'annotation', 'tags_x', 'openmoji_tags', 'Description', 'tags_y', 'LLM description']]\n",
    "final_df.columns = [\n",
    "    'emoji', 'hexcode', 'openmoji_annotation', 'openmoji_tags_1', 'openmoji_tags_2', 'emojipedia_description', 'llm_tags', 'llm_description'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.404461Z",
     "start_time": "2025-02-16T06:41:41.400184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#️⃣</td>\n",
       "      <td>0023-20e3</td>\n",
       "      <td>keycap: #</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*️⃣</td>\n",
       "      <td>002a-20e3</td>\n",
       "      <td>keycap: *</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>002d</td>\n",
       "      <td>hyphen-minus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hyphen, minus, dash, line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0️⃣</td>\n",
       "      <td>0030-20e3</td>\n",
       "      <td>keycap: 0</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1️⃣</td>\n",
       "      <td>0031-20e3</td>\n",
       "      <td>keycap: 1</td>\n",
       "      <td>keycap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji    hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "0   #️⃣  0023-20e3           keycap: #          keycap   \n",
       "1   *️⃣  002a-20e3           keycap: *          keycap   \n",
       "2     -       002d        hyphen-minus             NaN   \n",
       "3   0️⃣  0030-20e3           keycap: 0          keycap   \n",
       "4   1️⃣  0031-20e3           keycap: 1          keycap   \n",
       "\n",
       "             openmoji_tags_2 emojipedia_description llm_tags llm_description  \n",
       "0                        NaN                    NaN      NaN             NaN  \n",
       "1                        NaN                    NaN      NaN             NaN  \n",
       "2  hyphen, minus, dash, line                    NaN      NaN             NaN  \n",
       "3                        NaN                    NaN      NaN             NaN  \n",
       "4                        NaN                    NaN      NaN             NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:41.411552Z",
     "start_time": "2025-02-16T06:41:41.405230Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "    # Keep only letters, numbers, spaces, * and #\n",
    "    text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lemmatize the tokens\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ', '.join(tokens)\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = sorted(set(word.strip() for word in text.split(\",\")))\n",
    "    return ', '.join(unique_words)  # Join back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.320710Z",
     "start_time": "2025-02-16T06:41:41.412321Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:03<00:00, 1272.31it/s]\n",
      "100%|██████████| 4298/4298 [00:00<00:00, 2087680.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Clean openmoji_annotation column\n",
    "final_df[\"cleaned_annotations\"] = final_df[\"openmoji_annotation\"].progress_apply(clean_text)\n",
    "# Clean llm_tags\n",
    "final_df[\"cleaned_llm_tags\"] = final_df[\"llm_tags\"].progress_apply(clean_text)\n",
    "\n",
    "# List of columns to merge\n",
    "columns_to_merge = [\"cleaned_annotations\", \"openmoji_tags_1\", \"openmoji_tags_2\", \"cleaned_llm_tags\"]\n",
    "\n",
    "# Fill NaN with empty strings, then merge columns\n",
    "final_df[\"merged_tags\"] = final_df[columns_to_merge].fillna(\"\").agg(\n",
    "    lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.333968Z",
     "start_time": "2025-02-16T06:41:42.321305Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 508106.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "final_df[\"final_tags\"] = final_df[\"merged_tags\"].progress_apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.349792Z",
     "start_time": "2025-02-16T06:41:42.334674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:00<00:00, 347852.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Limiting only 2 sentences because the content is too long with too many references to other emoji, which might be more confusing later for the model to learn.\n",
    "\n",
    "\"\"\"\n",
    "Reference: Chat-GPT-4o\n",
    "Prompt: My df_images has a emojipedia_description column. Only keep the first two sentences in the column and remove the rest.\n",
    "\"\"\"\n",
    "# Function to keep only the first two sentences\n",
    "def keep_first_two_sentences(description):\n",
    "    if pd.isna(description):  # Handle missing values (NaNs)\n",
    "        return description\n",
    "    sentences = re.split(r'(?<=[.!?]) +', description.strip())  # Split by sentence-ending punctuation (., !, ?)\n",
    "    return ' '.join(sentences[:2])  # Return only the first two sentences\n",
    "\n",
    "# Apply the function to the 'llm_description' column\n",
    "final_df['emojipedia_description'] = final_df['emojipedia_description'].progress_apply(keep_first_two_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.394318Z",
     "start_time": "2025-02-16T06:41:42.350450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to handle concatenation with empty strings and NaN values\n",
    "def merge_descriptions(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['emojipedia_description']) and row['emojipedia_description'].strip():\n",
    "        parts.append(row['emojipedia_description'].strip())\n",
    "    if pd.notna(row['llm_description']) and row['llm_description'].strip():\n",
    "        parts.append(row['llm_description'].strip())\n",
    "    if pd.notna(row['final_tags']) and row['final_tags'].strip():\n",
    "        parts.append(\"Tags: \" + row['final_tags'].strip())\n",
    "    \n",
    "    return \" \".join(parts)\n",
    "\n",
    "# Apply the function to each row\n",
    "final_df['merged_description'] = final_df.apply(merge_descriptions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.421285Z",
     "start_time": "2025-02-16T06:41:42.399383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4298 entries, 0 to 4297\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   emoji                   4282 non-null   object\n",
      " 1   hexcode                 4298 non-null   object\n",
      " 2   openmoji_annotation     4282 non-null   object\n",
      " 3   openmoji_tags_1         1906 non-null   object\n",
      " 4   openmoji_tags_2         391 non-null    object\n",
      " 5   emojipedia_description  1885 non-null   object\n",
      " 6   llm_tags                2622 non-null   object\n",
      " 7   llm_description         2622 non-null   object\n",
      " 8   cleaned_annotations     4298 non-null   object\n",
      " 9   cleaned_llm_tags        4298 non-null   object\n",
      " 10  merged_tags             4298 non-null   object\n",
      " 11  final_tags              4298 non-null   object\n",
      " 12  merged_description      4298 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 436.6+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding using Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:42.430131Z",
     "start_time": "2025-02-16T06:41:42.423834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GPU (CUDA)\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:41:44.259671Z",
     "start_time": "2025-02-16T06:41:42.430909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6390bb9d1a1e411d9475b70a504ef49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Study\\College\\Project\\myvenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jyoti Prakash Uprety\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f42d236ee5542d3aed14d7c93d94c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df973484f27142229c3c769bb0b2ec5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ce30947fd245b7a6e0de48a5614145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbce5da7884dd7b93a08539c9dd066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba7f8c0911a4b6a97f281af5c78d28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb90fb6eec84b36a059e4eee92efee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c9c9ef4164455f905b7ebfd8487a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e40f94b4ad480cbbfbae790565dfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41597c2dd6f04c7885662163408955bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5f6dbc65a14090aed572301e398fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load SBERT model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_model = sbert_model.to(device)\n",
    "\n",
    "# Ensure text columns are strings\n",
    "# final_df[\"emojipedia_description\"] = final_df[\"emojipedia_description\"].fillna(\"\").astype(str)\n",
    "# final_df[\"llm_description\"] = final_df[\"llm_description\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Return SBERT embedding for a given text.\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return np.zeros(384, dtype=np.float32)  # Return zero vector for missing values (SBERT output size = 384)\n",
    "    return sbert_model.encode(text).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:42:28.951601Z",
     "start_time": "2025-02-16T06:41:44.261817Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4298/4298 [00:24<00:00, 176.10it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reference: https://sbert.net/\n",
    "\"\"\"\n",
    "\n",
    "# Apply SBERT embeddings to each columns\n",
    "# print(\"Embedding final_tags...\")\n",
    "# final_df[\"tags_embedding\"] = final_df[\"final_tags\"].progress_apply(embed_text)\n",
    "# \n",
    "# print(\"Embedding emojipedia_description...\")\n",
    "# final_df[\"emojipedia_embedding\"] = final_df[\"emojipedia_description\"].progress_apply(embed_text)\n",
    "# \n",
    "# print(\"Embedding llm_description...\")\n",
    "# final_df[\"llm_embedding\"] = final_df[\"llm_description\"].progress_apply(embed_text)\n",
    "\n",
    "# Apply SBERT embedding to merged_description\n",
    "final_df[\"combined_embedding\"] = final_df[\"merged_description\"].progress_apply(embed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:42:42.926104Z",
     "start_time": "2025-02-16T06:42:42.924391Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_df[\"combined_embedding\"] = final_df.apply(\n",
    "#     lambda row: np.concatenate([row[\"tags_embedding\"], row[\"emojipedia_embedding\"], row[\"llm_embedding\"]]), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:43:04.193239Z",
     "start_time": "2025-02-16T06:43:04.173427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>openmoji_annotation</th>\n",
       "      <th>openmoji_tags_1</th>\n",
       "      <th>openmoji_tags_2</th>\n",
       "      <th>emojipedia_description</th>\n",
       "      <th>llm_tags</th>\n",
       "      <th>llm_description</th>\n",
       "      <th>cleaned_annotations</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>merged_description</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td></td>\n",
       "      <td>e380</td>\n",
       "      <td>no handshaking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hygiene, agreement, virus, meeting, spread, germs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>handshaking</td>\n",
       "      <td></td>\n",
       "      <td>handshaking, hygiene, agreement, virus, meetin...</td>\n",
       "      <td>agreement, germs, handshaking, hygiene, meetin...</td>\n",
       "      <td>Tags: agreement, germs, handshaking, hygiene, ...</td>\n",
       "      <td>[-3.558908e-05, 0.044717934, -0.06403463, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td></td>\n",
       "      <td>e381</td>\n",
       "      <td>web syndication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feed, RSS, atom feed, podcast, subscribe, web ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>web, syndication</td>\n",
       "      <td></td>\n",
       "      <td>web, syndication, feed, RSS, atom feed, podcas...</td>\n",
       "      <td>RSS, atom feed, feed, podcast, subscribe, synd...</td>\n",
       "      <td>Tags: RSS, atom feed, feed, podcast, subscribe...</td>\n",
       "      <td>[0.00016245765, -0.09156131, -0.08722453, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td></td>\n",
       "      <td>f000</td>\n",
       "      <td>windows</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>windows</td>\n",
       "      <td></td>\n",
       "      <td>windows, Microsoft</td>\n",
       "      <td>Microsoft, windows</td>\n",
       "      <td>Tags: Microsoft, windows</td>\n",
       "      <td>[-0.04373724, 0.0015834963, -0.07001482, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td></td>\n",
       "      <td>f77a</td>\n",
       "      <td>artstation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>art, brand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artstation</td>\n",
       "      <td></td>\n",
       "      <td>artstation, art, brand</td>\n",
       "      <td>art, artstation, brand</td>\n",
       "      <td>Tags: art, artstation, brand</td>\n",
       "      <td>[0.035061266, -0.004645714, -0.017120054, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td></td>\n",
       "      <td>f8ff</td>\n",
       "      <td>apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iOS, OSX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apple</td>\n",
       "      <td></td>\n",
       "      <td>apple, iOS, OSX</td>\n",
       "      <td>OSX, apple, iOS</td>\n",
       "      <td>Tags: OSX, apple, iOS</td>\n",
       "      <td>[0.0059461663, -0.02266322, 0.04228183, -0.044...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emoji hexcode openmoji_annotation openmoji_tags_1  \\\n",
       "4293         e380      no handshaking             NaN   \n",
       "4294         e381     web syndication             NaN   \n",
       "4295         f000             windows             NaN   \n",
       "4296         f77a          artstation             NaN   \n",
       "4297         f8ff               apple             NaN   \n",
       "\n",
       "                                        openmoji_tags_2  \\\n",
       "4293  hygiene, agreement, virus, meeting, spread, germs   \n",
       "4294  feed, RSS, atom feed, podcast, subscribe, web ...   \n",
       "4295                                          Microsoft   \n",
       "4296                                         art, brand   \n",
       "4297                                           iOS, OSX   \n",
       "\n",
       "     emojipedia_description llm_tags llm_description cleaned_annotations  \\\n",
       "4293                    NaN      NaN             NaN         handshaking   \n",
       "4294                    NaN      NaN             NaN    web, syndication   \n",
       "4295                    NaN      NaN             NaN             windows   \n",
       "4296                    NaN      NaN             NaN          artstation   \n",
       "4297                    NaN      NaN             NaN               apple   \n",
       "\n",
       "     cleaned_llm_tags                                        merged_tags  \\\n",
       "4293                   handshaking, hygiene, agreement, virus, meetin...   \n",
       "4294                   web, syndication, feed, RSS, atom feed, podcas...   \n",
       "4295                                                  windows, Microsoft   \n",
       "4296                                              artstation, art, brand   \n",
       "4297                                                     apple, iOS, OSX   \n",
       "\n",
       "                                             final_tags  \\\n",
       "4293  agreement, germs, handshaking, hygiene, meetin...   \n",
       "4294  RSS, atom feed, feed, podcast, subscribe, synd...   \n",
       "4295                                 Microsoft, windows   \n",
       "4296                             art, artstation, brand   \n",
       "4297                                    OSX, apple, iOS   \n",
       "\n",
       "                                     merged_description  \\\n",
       "4293  Tags: agreement, germs, handshaking, hygiene, ...   \n",
       "4294  Tags: RSS, atom feed, feed, podcast, subscribe...   \n",
       "4295                           Tags: Microsoft, windows   \n",
       "4296                       Tags: art, artstation, brand   \n",
       "4297                              Tags: OSX, apple, iOS   \n",
       "\n",
       "                                     combined_embedding  \n",
       "4293  [-3.558908e-05, 0.044717934, -0.06403463, -0.0...  \n",
       "4294  [0.00016245765, -0.09156131, -0.08722453, -0.0...  \n",
       "4295  [-0.04373724, 0.0015834963, -0.07001482, 0.008...  \n",
       "4296  [0.035061266, -0.004645714, -0.017120054, -0.0...  \n",
       "4297  [0.0059461663, -0.02266322, 0.04228183, -0.044...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:44:07.036953Z",
     "start_time": "2025-02-16T06:43:41.780933Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|██████████| 4298/4298 [00:46<00:00, 92.96it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"OpenMojiEmoji\", \"TwitterEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(final_df.iterrows(), total=len(final_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:45:30.357916Z",
     "start_time": "2025-02-16T06:45:30.337757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12510 entries, 0 to 12509\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             12510 non-null  object\n",
      " 1   combined_embedding  12510 non-null  object\n",
      " 2   image_path          12510 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 293.3+ KB\n"
     ]
    }
   ],
   "source": [
    "expanded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-16T06:45:35.425779Z",
     "start_time": "2025-02-16T06:45:35.198303Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "output_file = '../data/processed_emoji_dataset.parquet'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "expanded_df[['combined_embedding', 'image_path']].to_parquet(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
