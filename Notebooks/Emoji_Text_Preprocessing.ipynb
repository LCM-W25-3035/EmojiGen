{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.446344Z",
     "start_time": "2025-03-20T05:04:59.410735Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()\n",
    "\n",
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mac GPU (MPS)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.516864Z",
     "start_time": "2025-03-20T05:04:59.458645Z"
    }
   },
   "source": [
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')"
   ],
   "outputs": [],
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.527941Z",
     "start_time": "2025-03-20T05:04:59.518155Z"
    }
   },
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "# Convert 'unicode' column in emojipedia_df and llm_df to 'hexcode'\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5034/5034 [00:00<00:00, 1163697.44it/s]\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.537370Z",
     "start_time": "2025-03-20T05:04:59.528731Z"
    }
   },
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)"
   ],
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.546150Z",
     "start_time": "2025-03-20T05:04:59.539237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.lower()\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.lower()"
   ],
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.551276Z",
     "start_time": "2025-03-20T05:04:59.546805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecting specific groups of emojis to train the model\n",
    "openmoji_df = openmoji_df[openmoji_df[\"group\"].isin([\"smileys-emotion\", \"people-body\"])]\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"subgroups\"].isin([\"person-symbol\", \"emotion\"])]"
   ],
   "outputs": [],
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.555690Z",
     "start_time": "2025-03-20T05:04:59.552026Z"
    }
   },
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.560549Z",
     "start_time": "2025-03-20T05:04:59.556412Z"
    }
   },
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1f3c3-1f3fd-2640-27a1           4\n",
      "1f6b6-1f3ff-2642-27a1           4\n",
      "1f6b6-1f3ff-2640-27a1           4\n",
      "1f6b6-1f3fe-2640-27a1           4\n",
      "1f6b6-1f3fc-2640-27a1           4\n",
      "                               ..\n",
      "1f9d1-1f3fc-2764-1f9d1-1f3fd    2\n",
      "1f469-1f3ff-2764-1f468-1f3fd    2\n",
      "1f9d1-1f3fd-2764-1f9d1-1f3ff    2\n",
      "1f327                           2\n",
      "2601                            2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.564410Z",
     "start_time": "2025-03-20T05:04:59.561227Z"
    }
   },
   "source": [
    "# Removing duplicates\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ],
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.571532Z",
     "start_time": "2025-03-20T05:04:59.565092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the dataframes on 'hexcode' with left join on openmoji_df\n",
    "merged_df = openmoji_df.merge(llm_df, on='hexcode', how='left')"
   ],
   "outputs": [],
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.579822Z",
     "start_time": "2025-03-20T05:04:59.573508Z"
    }
   },
   "source": [
    "merged_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      "dtypes: float64(1), object(19)\n",
      "memory usage: 375.8+ KB\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Tags and Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.582801Z",
     "start_time": "2025-03-20T05:04:59.580583Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or pd.isna(text) or text.strip().lower() == \"nan\":  \n",
    "        return \"\"  # Return empty string for NaN or \"nan\" strings\n",
    "    text = text.lower().strip() # Convert to lowercase and remove unnecessary spaces\n",
    "    # Keep only letters, numbers, spaces, * and #\n",
    "    text = re.sub(r'[^a-z0-9\\s*#]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ', '.join(tokens)\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = [word.strip() for word in text.split(\",\")]  # Split by commas and strip spaces\n",
    "    unique_words = list(dict.fromkeys(words))\n",
    "    return ', '.join(unique_words)  # Join back into a string"
   ],
   "outputs": [],
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.596308Z",
     "start_time": "2025-03-20T05:04:59.583344Z"
    }
   },
   "source": [
    "# Clean openmoji_annotation column\n",
    "# Clean llm_tags\n",
    "merged_df[\"cleaned_llm_tags\"] = merged_df[\"tags_y\"].progress_apply(clean_text)\n",
    "\n",
    "# List of columns to merge (All tags)\n",
    "columns_to_merge = [\"tags_x\", \"cleaned_llm_tags\"]\n",
    "\n",
    "# Fill NaN with empty strings, then merge columns\n",
    "merged_df[\"merged_tags\"] = merged_df[columns_to_merge].fillna(\"\").agg(\n",
    "    lambda x: \", \".join(filter(None, map(str, x))), axis=1\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2404/2404 [00:00<00:00, 1846384.69it/s]\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.602302Z",
     "start_time": "2025-03-20T05:04:59.597065Z"
    }
   },
   "source": [
    "# Remove duplicates\n",
    "merged_df[\"final_tags\"] = merged_df[\"merged_tags\"].progress_apply(remove_duplicates)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2404/2404 [00:00<00:00, 1024289.60it/s]\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.623358Z",
     "start_time": "2025-03-20T05:04:59.602975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to handle concatenation with empty strings and NaN values\n",
    "def merge_descriptions(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['annotation']):\n",
    "        annotation = row['annotation'].strip()\n",
    "        if annotation:  # Ensure it's not empty after stripping\n",
    "            parts.append(annotation)\n",
    "    if pd.notna(row['LLM description']):\n",
    "        description = row['LLM description'].strip()\n",
    "        if description:\n",
    "            parts.append(description)\n",
    "    if pd.notna(row['final_tags']):\n",
    "        tags = row['final_tags'].strip()\n",
    "        if tags:\n",
    "            parts.append(f\"Tags: {tags}\")  # Ensure the \"Tags: \" prefix is only added if valid\n",
    "\n",
    "    return \". \".join(parts) if parts else None  # Return None if no valid parts\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df['merged_description'] = merged_df.apply(merge_descriptions, axis=1)"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.629875Z",
     "start_time": "2025-03-20T05:04:59.624301Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      " 20  cleaned_llm_tags       2404 non-null   object \n",
      " 21  merged_tags            2404 non-null   object \n",
      " 22  final_tags             2404 non-null   object \n",
      " 23  merged_description     2404 non-null   object \n",
      "dtypes: float64(1), object(23)\n",
      "memory usage: 450.9+ KB\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.638595Z",
     "start_time": "2025-03-20T05:04:59.630644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Duplicate smiley emoji records so that the model has enough to learn from\n",
    "\n",
    "# Filter rows with group \"smileys-emotion\"\n",
    "smileys_df = merged_df[merged_df['group'] == 'smileys-emotion']\n",
    "\n",
    "# Duplicate these rows 3 times\n",
    "duplicated_smileys_df = pd.concat([smileys_df] * 2, ignore_index=True)\n",
    "\n",
    "# Append back to the original DataFrame\n",
    "merged_df = pd.concat([merged_df, duplicated_smileys_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset to mix the records\n",
    "merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:04:59.645164Z",
     "start_time": "2025-03-20T05:04:59.639283Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2712 entries, 0 to 2711\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2712 non-null   object \n",
      " 1   hexcode                2712 non-null   object \n",
      " 2   group                  2712 non-null   object \n",
      " 3   subgroups              2712 non-null   object \n",
      " 4   annotation             2712 non-null   object \n",
      " 5   tags_x                 837 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2712 non-null   object \n",
      " 8   openmoji_date          2712 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2712 non-null   object \n",
      " 14  order                  2712 non-null   float64\n",
      " 15  character              1741 non-null   object \n",
      " 16  unicode_y              1741 non-null   object \n",
      " 17  short description      1741 non-null   object \n",
      " 18  tags_y                 1741 non-null   object \n",
      " 19  LLM description        1741 non-null   object \n",
      " 20  cleaned_llm_tags       2712 non-null   object \n",
      " 21  merged_tags            2712 non-null   object \n",
      " 22  final_tags             2712 non-null   object \n",
      " 23  merged_description     2712 non-null   object \n",
      "dtypes: float64(1), object(23)\n",
      "memory usage: 508.6+ KB\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Embedding Emoji Condition"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:05:03.096174Z",
     "start_time": "2025-03-20T05:04:59.646125Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Reference: https://huggingface.co/docs/transformers/model_doc/clip\n",
    "\"\"\"\n",
    "\n",
    "# Load CLIP's tokenizer and text model.\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:05:03.102881Z",
     "start_time": "2025-03-20T05:05:03.097423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Reference: ChatGPT o3-mini-high\n",
    "Prompt: Write a code to embed my description column in my df using CLIP-vit-base-patch32. Use Mean Pooling + L2 Normalization method to generate embeddings.\n",
    "\n",
    "Reason: We're using Mean Pooling + L2 Normalization to retain fine-grained meanings related to gender, skin tone, emotions, and objects. We're also using L2 Normalization because they have a consistent scale, reducing variance in GAN training.\n",
    "\"\"\"\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean pool the token embeddings.\"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state  # (batch_size, sequence_length, hidden_dim)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, dim=1) / torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        # Adjust the zero vector size to match CLIP's output dimension (512 for clip-vit-base-patch32)\n",
    "        return np.zeros(512, dtype=np.float32)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = clip_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=77)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        output = clip_model(**inputs)\n",
    "    \n",
    "    # Pool the token embeddings (mean pooling)\n",
    "    pooled_embedding = mean_pooling(output, inputs[\"attention_mask\"])\n",
    "    \n",
    "    # Optionally, you might want to L2 normalize the pooled embedding:\n",
    "    pooled_embedding = torch.nn.functional.normalize(pooled_embedding, p=2, dim=-1)\n",
    "    \n",
    "    return pooled_embedding.squeeze().cpu().numpy().astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:04.411327Z",
     "start_time": "2025-03-20T05:05:03.106475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply CLIP embedding to your dataset\n",
    "merged_df[\"combined_embedding\"] = merged_df[\"merged_description\"].progress_apply(embed_text)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2712/2712 [01:01<00:00, 44.24it/s]\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:04.431731Z",
     "start_time": "2025-03-20T05:06:04.412720Z"
    }
   },
   "source": "merged_df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   emoji           hexcode            group        subgroups  \\\n",
       "0     🧑🏼       1f9d1-1f3fc      people-body           person   \n",
       "1  🚶🏼‍➡️  1f6b6-1f3fc-27a1      people-body  person-activity   \n",
       "2  ⛹️‍♀️         26f9-2640      people-body     person-sport   \n",
       "3     👫🏽       1f46b-1f3fd      people-body           family   \n",
       "4      😺             1f63a  smileys-emotion         cat-face   \n",
       "\n",
       "                                      annotation  \\\n",
       "0                 person: medium-light skin tone   \n",
       "1                    person walking facing right   \n",
       "2                            woman bouncing ball   \n",
       "3  woman and man holding hands: medium skin tone   \n",
       "4                                   grinning cat   \n",
       "\n",
       "                                    tags_x openmoji_tags   openmoji_author  \\\n",
       "0                                      NaN           NaN  Johanna Wellnitz   \n",
       "1                                      NaN           NaN  Johanna Wellnitz   \n",
       "2                              ball, woman           NaN     Florian Nagel   \n",
       "3                                      NaN           NaN       Lisa Schulz   \n",
       "4  cat, face, grinning, mouth, open, smile           NaN       Emily Jäger   \n",
       "\n",
       "  openmoji_date skintone  ... character      unicode_y  \\\n",
       "0    2018-04-18        2  ...        🧑🏼  U+1F9D1 1F3FC   \n",
       "1    2018-04-18        2  ...       NaN            NaN   \n",
       "2    2019-05-07      NaN  ...       NaN            NaN   \n",
       "3    2018-04-18        3  ...        👫🏽  U+1F46B 1F3FD   \n",
       "4    2018-04-18      NaN  ...         😺        U+1F63A   \n",
       "\n",
       "                              short description  \\\n",
       "0                 PERSON MEDIUM-LIGHT SKIN TONE   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3  WOMAN AND MAN HOLDING HANDS MEDIUM SKIN TONE   \n",
       "4                                  GRINNING CAT   \n",
       "\n",
       "                                              tags_y  \\\n",
       "0  [person, human, medium-light skin tone, indivi...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [couple, love, partnership, unity, medium skin...   \n",
       "4  [cat, pet, happiness, playfulness, affection, ...   \n",
       "\n",
       "                                     LLM description cleaned_llm_tags  \\\n",
       "0  This emoji represents a person with a medium-l...                    \n",
       "1                                                NaN                    \n",
       "2                                                NaN                    \n",
       "3  This emoji represents a couple, specifically a...                    \n",
       "4  This emoji represents a grinning cat, expressi...                    \n",
       "\n",
       "                               merged_tags  \\\n",
       "0                                            \n",
       "1                                            \n",
       "2                              ball, woman   \n",
       "3                                            \n",
       "4  cat, face, grinning, mouth, open, smile   \n",
       "\n",
       "                                final_tags  \\\n",
       "0                                            \n",
       "1                                            \n",
       "2                              ball, woman   \n",
       "3                                            \n",
       "4  cat, face, grinning, mouth, open, smile   \n",
       "\n",
       "                                  merged_description  \\\n",
       "0  person: medium-light skin tone. This emoji rep...   \n",
       "1                        person walking facing right   \n",
       "2             woman bouncing ball. Tags: ball, woman   \n",
       "3  woman and man holding hands: medium skin tone....   \n",
       "4  grinning cat. This emoji represents a grinning...   \n",
       "\n",
       "                                  combined_embedding  \n",
       "0  [0.003767395, 0.014542699, 0.003556244, 0.0125...  \n",
       "1  [0.06663352, -0.04734618, -0.012481797, 0.0329...  \n",
       "2  [0.0677169, 0.015118559, 0.020386862, 0.023723...  \n",
       "3  [-0.018861774, -0.014128143, -0.031488158, 0.0...  \n",
       "4  [-0.023747135, -0.023023505, 0.0090910075, 0.0...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>character</th>\n",
       "      <th>unicode_y</th>\n",
       "      <th>short description</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>LLM description</th>\n",
       "      <th>cleaned_llm_tags</th>\n",
       "      <th>merged_tags</th>\n",
       "      <th>final_tags</th>\n",
       "      <th>merged_description</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🧑🏼</td>\n",
       "      <td>1f9d1-1f3fc</td>\n",
       "      <td>people-body</td>\n",
       "      <td>person</td>\n",
       "      <td>person: medium-light skin tone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johanna Wellnitz</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>🧑🏼</td>\n",
       "      <td>U+1F9D1 1F3FC</td>\n",
       "      <td>PERSON MEDIUM-LIGHT SKIN TONE</td>\n",
       "      <td>[person, human, medium-light skin tone, indivi...</td>\n",
       "      <td>This emoji represents a person with a medium-l...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>person: medium-light skin tone. This emoji rep...</td>\n",
       "      <td>[0.003767395, 0.014542699, 0.003556244, 0.0125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>🚶🏼‍➡️</td>\n",
       "      <td>1f6b6-1f3fc-27a1</td>\n",
       "      <td>people-body</td>\n",
       "      <td>person-activity</td>\n",
       "      <td>person walking facing right</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johanna Wellnitz</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>person walking facing right</td>\n",
       "      <td>[0.06663352, -0.04734618, -0.012481797, 0.0329...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>⛹️‍♀️</td>\n",
       "      <td>26f9-2640</td>\n",
       "      <td>people-body</td>\n",
       "      <td>person-sport</td>\n",
       "      <td>woman bouncing ball</td>\n",
       "      <td>ball, woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florian Nagel</td>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>ball, woman</td>\n",
       "      <td>ball, woman</td>\n",
       "      <td>woman bouncing ball. Tags: ball, woman</td>\n",
       "      <td>[0.0677169, 0.015118559, 0.020386862, 0.023723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>👫🏽</td>\n",
       "      <td>1f46b-1f3fd</td>\n",
       "      <td>people-body</td>\n",
       "      <td>family</td>\n",
       "      <td>woman and man holding hands: medium skin tone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lisa Schulz</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>👫🏽</td>\n",
       "      <td>U+1F46B 1F3FD</td>\n",
       "      <td>WOMAN AND MAN HOLDING HANDS MEDIUM SKIN TONE</td>\n",
       "      <td>[couple, love, partnership, unity, medium skin...</td>\n",
       "      <td>This emoji represents a couple, specifically a...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>woman and man holding hands: medium skin tone....</td>\n",
       "      <td>[-0.018861774, -0.014128143, -0.031488158, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>😺</td>\n",
       "      <td>1f63a</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>cat-face</td>\n",
       "      <td>grinning cat</td>\n",
       "      <td>cat, face, grinning, mouth, open, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily Jäger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>😺</td>\n",
       "      <td>U+1F63A</td>\n",
       "      <td>GRINNING CAT</td>\n",
       "      <td>[cat, pet, happiness, playfulness, affection, ...</td>\n",
       "      <td>This emoji represents a grinning cat, expressi...</td>\n",
       "      <td></td>\n",
       "      <td>cat, face, grinning, mouth, open, smile</td>\n",
       "      <td>cat, face, grinning, mouth, open, smile</td>\n",
       "      <td>grinning cat. This emoji represents a grinning...</td>\n",
       "      <td>[-0.023747135, -0.023023505, 0.0090910075, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 189
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:09.685754Z",
     "start_time": "2025-03-20T05:06:04.432529Z"
    }
   },
   "source": [
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "# brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"TwitterEmoji\"]\n",
    "brands = [\"OpenMojiEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|██████████| 2712/2712 [00:05<00:00, 517.84it/s]\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:09.692921Z",
     "start_time": "2025-03-20T05:06:09.686452Z"
    }
   },
   "source": [
    "expanded_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2712 entries, 0 to 2711\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             2712 non-null   object\n",
      " 1   combined_embedding  2712 non-null   object\n",
      " 2   image_path          2712 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 63.7+ KB\n"
     ]
    }
   ],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:09.837613Z",
     "start_time": "2025-03-20T05:06:09.693567Z"
    }
   },
   "source": [
    "output_file = '../data/processed_emoji_dataset.parquet'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "expanded_df[['combined_embedding', 'image_path']].to_parquet(output_file, index=False)"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T05:06:09.839609Z",
     "start_time": "2025-03-20T05:06:09.838295Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 192
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
