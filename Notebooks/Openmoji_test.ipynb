{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.815199Z",
     "start_time": "2025-03-16T04:51:58.808606Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Download NLTK data files (only need to run once)\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Apply tqdm to all .apply() functions by using progress_apply\n",
    "tqdm.pandas()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bikinghimire/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.866208Z",
     "start_time": "2025-03-16T04:51:58.832092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reading the dataset\n",
    "openmoji_df = pd.read_csv('../data/openmoji.csv')\n",
    "llm_df = pd.read_parquet('../data/llmemoji.parquet')"
   ],
   "id": "22db956a9b2ef926",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.878661Z",
     "start_time": "2025-03-16T04:51:58.867485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert Unicode string (e.g., 'U+1F600', 'U+263A,FE0F') to hex code ('1F600', '263A-FE0F').\n",
    "\n",
    "def unicode_to_hex(unicode_str):\n",
    "    unicode_str = unicode_str.replace(\",\", \" \")  # Replace commas with spaces\n",
    "    # First splitting the input string to a list of substrings\n",
    "    # Loops though each substring\n",
    "    # Removes the U+ prefix from each substring\n",
    "    hex_values = [u.replace(\"U+\", \"\") for u in unicode_str.split()]\n",
    "    # Join the values with hyphens\n",
    "    return \"-\".join(hex_values)\n",
    "\n",
    "llm_df['hexcode'] = llm_df['unicode'].progress_apply(unicode_to_hex)"
   ],
   "id": "dcddd19af081e9b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5034/5034 [00:00<00:00, 1115202.36it/s]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.891378Z",
     "start_time": "2025-03-16T04:51:58.882654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making the hexcode uniform in all 3 dataframes for merging\n",
    "# removing -f30f (differentiation between image type emoji and textual type emoji)\n",
    "# removing -200d (differentiation for emoji with skin-tone)\n",
    "\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.replace('-200D', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-FE0F', '', regex=True)\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.replace('-200D', '', regex=True)"
   ],
   "id": "cf8f924f7b1b800f",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.896080Z",
     "start_time": "2025-03-16T04:51:58.892947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openmoji_df['hexcode'] = openmoji_df['hexcode'].str.lower()\n",
    "llm_df['hexcode'] = llm_df['hexcode'].str.lower()"
   ],
   "id": "3d75cf4a3741b21e",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.899745Z",
     "start_time": "2025-03-16T04:51:58.896740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# openmoji_df = openmoji_df[openmoji_df[\"group\"] == \"smileys-emotion\"]\n",
    "openmoji_df = openmoji_df[openmoji_df[\"group\"].isin([\"smileys-emotion\", \"people-body\"])]\n",
    "openmoji_df = openmoji_df[~openmoji_df[\"subgroups\"].isin([\"person-symbol\", \"emotion\"])]\n",
    "# Removing Skin tones\n",
    "# openmoji_df = openmoji_df[~openmoji_df['hexcode'].str.contains('1f3fb|1f3fc|1f3fd|1f3fe|1f3ff', regex=True)]\n",
    "# Removing extra emojis"
   ],
   "id": "bd2b5b5f8ab496e3",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.911088Z",
     "start_time": "2025-03-16T04:51:58.907426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = openmoji_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)"
   ],
   "id": "62b861afc3567ab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.917118Z",
     "start_time": "2025-03-16T04:51:58.912016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking for duplicates\n",
    "duplicate_counts = llm_df['hexcode'].value_counts()\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]\n",
    "print(duplicates)\n",
    "llm_df = llm_df[~llm_df.duplicated(subset=['hexcode'], keep=False)]"
   ],
   "id": "92e4c50e911ad511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexcode\n",
      "1f3c3-1f3fd-2640-27a1           4\n",
      "1f6b6-1f3ff-2642-27a1           4\n",
      "1f6b6-1f3ff-2640-27a1           4\n",
      "1f6b6-1f3fe-2640-27a1           4\n",
      "1f6b6-1f3fc-2640-27a1           4\n",
      "                               ..\n",
      "1f9d1-1f3fc-2764-1f9d1-1f3fd    2\n",
      "1f469-1f3ff-2764-1f468-1f3fd    2\n",
      "1f9d1-1f3fd-2764-1f9d1-1f3ff    2\n",
      "1f327                           2\n",
      "2601                            2\n",
      "Name: count, Length: 1160, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.928668Z",
     "start_time": "2025-03-16T04:51:58.923573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the dataframes on 'hexcode'\n",
    "merged_df = openmoji_df.merge(llm_df, on='hexcode', how='left')  # Changed outer merge to left\n",
    "# Convert hexcode to lowercase\n",
    "merged_df['hexcode'] = merged_df['hexcode'].str.lower()"
   ],
   "id": "f0c959a351ae1a5f",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.940418Z",
     "start_time": "2025-03-16T04:51:58.934444Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.info()",
   "id": "e3e86359b7fb8c85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      "dtypes: float64(1), object(19)\n",
      "memory usage: 375.8+ KB\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.963140Z",
     "start_time": "2025-03-16T04:51:58.945212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to handle concatenation with empty strings and NaN values\n",
    "def merge_descriptions(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['annotation']) and row['annotation'].strip():\n",
    "        parts.append(row['annotation'].strip())\n",
    "    if pd.notna(row['LLM description']) and row['LLM description'].strip():\n",
    "        parts.append(row['LLM description'].strip())\n",
    "    \n",
    "    return \". \".join(parts)\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df['merged_description'] = merged_df.apply(merge_descriptions, axis=1)"
   ],
   "id": "30100c9e051a69c7",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.966413Z",
     "start_time": "2025-03-16T04:51:58.964093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use GPU if available\n",
    "\"\"\"\n",
    "Reference: https://pytorch.org/get-started/locally/\n",
    "\"\"\"\n",
    "\n",
    "# Check for NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use CUDA (NVIDIA GPU)\n",
    "    print(\"Using NVIDIA GPU (CUDA)\")\n",
    "\n",
    "# Check for Mac Silicon GPU (MPS)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (Mac Silicon GPU)\n",
    "    print(\"Using Mac GPU (MPS)\")\n",
    "\n",
    "# Default to CPU if no GPU is available\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "id": "3d2bd3f5931cf605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mac GPU (MPS)\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.969094Z",
     "start_time": "2025-03-16T04:51:58.967189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load SBERT model\n",
    "# sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# sbert_model = sbert_model.to(device)\n",
    "# \n",
    "# # Return SBERT embedding for a given text.\n",
    "# def embed_text(text):\n",
    "#     if pd.isna(text) or text.strip() == \"\":\n",
    "#         return np.zeros(384, dtype=np.float32)  # Return zero vector for missing values (SBERT output size = 384)\n",
    "#     return sbert_model.encode(text).astype(np.float32)"
   ],
   "id": "944c67aa820a32bb",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:51:58.971408Z",
     "start_time": "2025-03-16T04:51:58.970112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Applu SBERT embedding to annotation in openmoji_df\n",
    "# merged_df[\"combined_embedding\"] = merged_df[\"merged_description\"].progress_apply(embed_text)"
   ],
   "id": "aa51b01dec330957",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:51.587066Z",
     "start_time": "2025-03-16T04:51:58.972050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "import torch\n",
    "\n",
    "# Load CLIP's tokenizer and text model.\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = clip_model.to(device)\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean pool the token embeddings.\"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state  # (batch_size, sequence_length, hidden_dim)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, dim=1) / torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        # Adjust the zero vector size to match CLIP's output dimension (512 for clip-vit-base-patch32)\n",
    "        return np.zeros(512, dtype=np.float32)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = clip_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=77)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        output = clip_model(**inputs)\n",
    "    \n",
    "    # Pool the token embeddings (mean pooling)\n",
    "    pooled_embedding = mean_pooling(output, inputs[\"attention_mask\"])\n",
    "    \n",
    "    # Optionally, you might want to L2 normalize the pooled embedding:\n",
    "    pooled_embedding = torch.nn.functional.normalize(pooled_embedding, p=2, dim=-1)\n",
    "    \n",
    "    return pooled_embedding.squeeze().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# Apply CLIP embedding to your dataset\n",
    "merged_df[\"combined_embedding\"] = merged_df[\"merged_description\"].progress_apply(embed_text)"
   ],
   "id": "ae035082e869c980",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2404/2404 [00:48<00:00, 49.08it/s]\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:51.601465Z",
     "start_time": "2025-03-16T04:52:51.589787Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.head()",
   "id": "1c7fb7ed677f6fca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  emoji hexcode            group     subgroups  \\\n",
       "0     üòÄ   1f600  smileys-emotion  face-smiling   \n",
       "1     üòÉ   1f603  smileys-emotion  face-smiling   \n",
       "2     üòÑ   1f604  smileys-emotion  face-smiling   \n",
       "3     üòÅ   1f601  smileys-emotion  face-smiling   \n",
       "4     üòÜ   1f606  smileys-emotion  face-smiling   \n",
       "\n",
       "                        annotation                                tags_x  \\\n",
       "0                    grinning face                            face, grin   \n",
       "1      grinning face with big eyes              face, mouth, open, smile   \n",
       "2  grinning face with smiling eyes         eye, face, mouth, open, smile   \n",
       "3   beaming face with smiling eyes                eye, face, grin, smile   \n",
       "4          grinning squinting face  face, laugh, mouth, satisfied, smile   \n",
       "\n",
       "  openmoji_tags openmoji_author openmoji_date skintone  ...  \\\n",
       "0           NaN     Emily J√§ger    2018-04-18      NaN  ...   \n",
       "1           NaN     Emily J√§ger    2018-04-18      NaN  ...   \n",
       "2           NaN     Emily J√§ger    2018-04-18      NaN  ...   \n",
       "3           NaN     Emily J√§ger    2018-04-18      NaN  ...   \n",
       "4           NaN     Emily J√§ger    2018-04-18      NaN  ...   \n",
       "\n",
       "  skintone_base_hexcode unicode_x order character  unicode_y  \\\n",
       "0                   NaN         1   1.0         üòÄ    U+1F600   \n",
       "1                   NaN       0.6   2.0         üòÉ    U+1F603   \n",
       "2                   NaN       0.6   3.0         üòÑ    U+1F604   \n",
       "3                   NaN       0.6   4.0         üòÅ    U+1F601   \n",
       "4                   NaN       0.6   5.0         üòÜ    U+1F606   \n",
       "\n",
       "                 short description  \\\n",
       "0                    GRINNING FACE   \n",
       "1      GRINNING FACE WITH BIG EYES   \n",
       "2  GRINNING FACE WITH SMILING EYES   \n",
       "3   BEAMING FACE WITH SMILING EYES   \n",
       "4          GRINNING SQUINTING FACE   \n",
       "\n",
       "                                              tags_y  \\\n",
       "0  [smiling, happy, amusement, positive, friendly...   \n",
       "1  [smiling, happiness, joy, amusement, face, emo...   \n",
       "2  [smiling, happy, amusement, joy, laughter, con...   \n",
       "3      [happy, joy, delight, smiling, face, emotion]   \n",
       "4  [smiling, happy, humor, amusement, laughter, f...   \n",
       "\n",
       "                                     LLM description  \\\n",
       "0  This emoji represents a smiling face with a br...   \n",
       "1  This emoji represents a smiling face with a wi...   \n",
       "2  This emoji represents a smiling face with happ...   \n",
       "3  This emoji represents a beaming face with smil...   \n",
       "4  This emoji represents a smiling face with squi...   \n",
       "\n",
       "                                  merged_description  \\\n",
       "0  grinning face. This emoji represents a smiling...   \n",
       "1  grinning face with big eyes. This emoji repres...   \n",
       "2  grinning face with smiling eyes. This emoji re...   \n",
       "3  beaming face with smiling eyes. This emoji rep...   \n",
       "4  grinning squinting face. This emoji represents...   \n",
       "\n",
       "                                  combined_embedding  \n",
       "0  [-0.009248982, -0.047417954, -0.0052406015, 0....  \n",
       "1  [0.015901517, -0.033154536, -0.010774338, 0.04...  \n",
       "2  [-0.0005932258, -0.0486032, -0.00471365, 0.028...  \n",
       "3  [-0.0002108886, -0.035330746, -0.0045009465, 0...  \n",
       "4  [0.0041811396, -0.039693166, -0.010858571, 0.0...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>hexcode</th>\n",
       "      <th>group</th>\n",
       "      <th>subgroups</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags_x</th>\n",
       "      <th>openmoji_tags</th>\n",
       "      <th>openmoji_author</th>\n",
       "      <th>openmoji_date</th>\n",
       "      <th>skintone</th>\n",
       "      <th>...</th>\n",
       "      <th>skintone_base_hexcode</th>\n",
       "      <th>unicode_x</th>\n",
       "      <th>order</th>\n",
       "      <th>character</th>\n",
       "      <th>unicode_y</th>\n",
       "      <th>short description</th>\n",
       "      <th>tags_y</th>\n",
       "      <th>LLM description</th>\n",
       "      <th>merged_description</th>\n",
       "      <th>combined_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üòÄ</td>\n",
       "      <td>1f600</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>face, grin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily J√§ger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>üòÄ</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>GRINNING FACE</td>\n",
       "      <td>[smiling, happy, amusement, positive, friendly...</td>\n",
       "      <td>This emoji represents a smiling face with a br...</td>\n",
       "      <td>grinning face. This emoji represents a smiling...</td>\n",
       "      <td>[-0.009248982, -0.047417954, -0.0052406015, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòÉ</td>\n",
       "      <td>1f603</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "      <td>face, mouth, open, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily J√§ger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>üòÉ</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>GRINNING FACE WITH BIG EYES</td>\n",
       "      <td>[smiling, happiness, joy, amusement, face, emo...</td>\n",
       "      <td>This emoji represents a smiling face with a wi...</td>\n",
       "      <td>grinning face with big eyes. This emoji repres...</td>\n",
       "      <td>[0.015901517, -0.033154536, -0.010774338, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòÑ</td>\n",
       "      <td>1f604</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>eye, face, mouth, open, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily J√§ger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>üòÑ</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>GRINNING FACE WITH SMILING EYES</td>\n",
       "      <td>[smiling, happy, amusement, joy, laughter, con...</td>\n",
       "      <td>This emoji represents a smiling face with happ...</td>\n",
       "      <td>grinning face with smiling eyes. This emoji re...</td>\n",
       "      <td>[-0.0005932258, -0.0486032, -0.00471365, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòÅ</td>\n",
       "      <td>1f601</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "      <td>eye, face, grin, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily J√§ger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>üòÅ</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>BEAMING FACE WITH SMILING EYES</td>\n",
       "      <td>[happy, joy, delight, smiling, face, emotion]</td>\n",
       "      <td>This emoji represents a beaming face with smil...</td>\n",
       "      <td>beaming face with smiling eyes. This emoji rep...</td>\n",
       "      <td>[-0.0002108886, -0.035330746, -0.0045009465, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÜ</td>\n",
       "      <td>1f606</td>\n",
       "      <td>smileys-emotion</td>\n",
       "      <td>face-smiling</td>\n",
       "      <td>grinning squinting face</td>\n",
       "      <td>face, laugh, mouth, satisfied, smile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily J√§ger</td>\n",
       "      <td>2018-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>üòÜ</td>\n",
       "      <td>U+1F606</td>\n",
       "      <td>GRINNING SQUINTING FACE</td>\n",
       "      <td>[smiling, happy, humor, amusement, laughter, f...</td>\n",
       "      <td>This emoji represents a smiling face with squi...</td>\n",
       "      <td>grinning squinting face. This emoji represents...</td>\n",
       "      <td>[0.0041811396, -0.039693166, -0.010858571, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:51.609086Z",
     "start_time": "2025-03-16T04:52:51.602183Z"
    }
   },
   "cell_type": "code",
   "source": "merged_df.info()",
   "id": "94391aecc43c6a05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   emoji                  2404 non-null   object \n",
      " 1   hexcode                2404 non-null   object \n",
      " 2   group                  2404 non-null   object \n",
      " 3   subgroups              2404 non-null   object \n",
      " 4   annotation             2404 non-null   object \n",
      " 5   tags_x                 529 non-null    object \n",
      " 6   openmoji_tags          0 non-null      object \n",
      " 7   openmoji_author        2404 non-null   object \n",
      " 8   openmoji_date          2404 non-null   object \n",
      " 9   skintone               1875 non-null   object \n",
      " 10  skintone_combination   2198 non-null   object \n",
      " 11  skintone_base_emoji    2198 non-null   object \n",
      " 12  skintone_base_hexcode  2198 non-null   object \n",
      " 13  unicode_x              2404 non-null   object \n",
      " 14  order                  2404 non-null   float64\n",
      " 15  character              1453 non-null   object \n",
      " 16  unicode_y              1453 non-null   object \n",
      " 17  short description      1453 non-null   object \n",
      " 18  tags_y                 1453 non-null   object \n",
      " 19  LLM description        1453 non-null   object \n",
      " 20  merged_description     2404 non-null   object \n",
      " 21  combined_embedding     2404 non-null   object \n",
      "dtypes: float64(1), object(21)\n",
      "memory usage: 413.3+ KB\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:51.618161Z",
     "start_time": "2025-03-16T04:52:51.609632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/test_openmoji_dataset.csv'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "merged_df[['hexcode', 'group', 'subgroups', 'annotation', 'LLM description']].to_csv(output_file, index=False)"
   ],
   "id": "514dbe7faa67472c",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:51.620708Z",
     "start_time": "2025-03-16T04:52:51.618915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# \n",
    "# # Define base image path and brands\n",
    "# image_base_path = \"../data/tensor_images/OpenmojiEmoji\"\n",
    "# \n",
    "# # Function to find all available image paths for a given hexcode\n",
    "# def get_image_paths(hexcode):\n",
    "#     image_paths = {}\n",
    "#             \n",
    "#     expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "#         \n",
    "#     if expected_filename in os.listdir(image_base_path):\n",
    "#         image_paths = os.path.join(image_base_path, expected_filename)\n",
    "# \n",
    "#     return image_paths\n",
    "# \n",
    "# # Expand dataframe with tqdm progress bar\n",
    "# expanded_rows = []\n",
    "# for _, row in tqdm(openmoji_df.iterrows(), total=len(openmoji_df), desc=\"Processing Hexcodes\"):\n",
    "#     hexcode = row[\"hexcode\"]\n",
    "#     embedding = row[\"combined_embedding\"]\n",
    "# \n",
    "#     image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "#     \n",
    "#     if image_paths:\n",
    "#         expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": image_paths})\n",
    "#     else:\n",
    "#         # If no images exist, optionally add a row with NaN for image_path\n",
    "#         expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "# \n",
    "# # Convert to DataFrame\n",
    "# expanded_df = pd.DataFrame(expanded_rows)\n",
    "# \n",
    "# # Optional: Drop rows where no image is found\n",
    "# expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ],
   "id": "6243c9bc45694c0b",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:56.279271Z",
     "start_time": "2025-03-16T04:52:51.622190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define base image path and brands\n",
    "image_base_path = \"../data/tensor_images/\"\n",
    "# brands = [\"GoogleEmoji\", \"JoyPixelsEmoji\", \"TwitterEmoji\"]\n",
    "brands = [\"OpenMojiEmoji\"]\n",
    "\n",
    "# Function to find all available image paths for a given hexcode\n",
    "def get_image_paths(hexcode):\n",
    "    image_paths = {}\n",
    "    \n",
    "    for brand in brands:\n",
    "        brand_path = os.path.join(image_base_path, brand)\n",
    "        if not os.path.exists(brand_path): # Skip if folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        expected_filename = f\"{hexcode}.pt\"  # Adjust based on actual format\n",
    "        \n",
    "        if expected_filename in os.listdir(brand_path):\n",
    "            image_paths[brand] = os.path.join(brand_path, expected_filename)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Expand dataframe with tqdm progress bar\n",
    "expanded_rows = []\n",
    "for _, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing Hexcodes\"):\n",
    "    hexcode = row[\"hexcode\"]\n",
    "    embedding = row[\"combined_embedding\"]\n",
    "\n",
    "    image_paths = get_image_paths(hexcode)  # Get list of image paths\n",
    "    \n",
    "    if image_paths:  # If images exist, create multiple rows\n",
    "        for brand, path in image_paths.items():\n",
    "            expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": path})\n",
    "    else:\n",
    "        # If no images exist, optionally add a row with NaN for image_path\n",
    "        expanded_rows.append({\"hexcode\": hexcode, \"combined_embedding\": embedding, \"image_path\": None})\n",
    "\n",
    "# Convert to DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Optional: Drop rows where no image is found\n",
    "expanded_df = expanded_df.dropna(subset=[\"image_path\"]).reset_index(drop=True)"
   ],
   "id": "ff234b4b290d403",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Hexcodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2404/2404 [00:04<00:00, 517.46it/s]\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:56.291649Z",
     "start_time": "2025-03-16T04:52:56.285700Z"
    }
   },
   "cell_type": "code",
   "source": "expanded_df.info()",
   "id": "a0f598359f02a73d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2404 entries, 0 to 2403\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   hexcode             2404 non-null   object\n",
      " 1   combined_embedding  2404 non-null   object\n",
      " 2   image_path          2404 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 56.5+ KB\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:56.296947Z",
     "start_time": "2025-03-16T04:52:56.292250Z"
    }
   },
   "cell_type": "code",
   "source": "expanded_df.head()",
   "id": "c4182491ecfe6412",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  hexcode                                 combined_embedding  \\\n",
       "0   1f600  [-0.009248982, -0.047417954, -0.0052406015, 0....   \n",
       "1   1f603  [0.015901517, -0.033154536, -0.010774338, 0.04...   \n",
       "2   1f604  [-0.0005932258, -0.0486032, -0.00471365, 0.028...   \n",
       "3   1f601  [-0.0002108886, -0.035330746, -0.0045009465, 0...   \n",
       "4   1f606  [0.0041811396, -0.039693166, -0.010858571, 0.0...   \n",
       "\n",
       "                                     image_path  \n",
       "0  ../data/tensor_images/OpenMojiEmoji/1f600.pt  \n",
       "1  ../data/tensor_images/OpenMojiEmoji/1f603.pt  \n",
       "2  ../data/tensor_images/OpenMojiEmoji/1f604.pt  \n",
       "3  ../data/tensor_images/OpenMojiEmoji/1f601.pt  \n",
       "4  ../data/tensor_images/OpenMojiEmoji/1f606.pt  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hexcode</th>\n",
       "      <th>combined_embedding</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1f600</td>\n",
       "      <td>[-0.009248982, -0.047417954, -0.0052406015, 0....</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/1f600.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1f603</td>\n",
       "      <td>[0.015901517, -0.033154536, -0.010774338, 0.04...</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/1f603.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f604</td>\n",
       "      <td>[-0.0005932258, -0.0486032, -0.00471365, 0.028...</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/1f604.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f601</td>\n",
       "      <td>[-0.0002108886, -0.035330746, -0.0045009465, 0...</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/1f601.pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1f606</td>\n",
       "      <td>[0.0041811396, -0.039693166, -0.010858571, 0.0...</td>\n",
       "      <td>../data/tensor_images/OpenMojiEmoji/1f606.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:56.377044Z",
     "start_time": "2025-03-16T04:52:56.297539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = '../data/processed_openmoji_dataset.parquet'\n",
    "\n",
    "# Check if the file exists and remove it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Now save the DataFrame as Parquet\n",
    "expanded_df[['combined_embedding', 'image_path']].to_parquet(output_file, index=False)"
   ],
   "id": "fd53a3cd842a3dbf",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:52:56.379362Z",
     "start_time": "2025-03-16T04:52:56.377944Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f64ee60a876ee87b",
   "outputs": [],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
