{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:06:15.510345Z",
     "start_time": "2025-02-13T14:06:14.952155Z"
    },
    "collapsed": true
   },
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db28cd2c73f33e59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:06:25.104846Z",
     "start_time": "2025-02-13T14:06:24.732475Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "# Load the dataset\n",
    "#Load the sticker dataset\n",
    "df = pd.read_parquet('../data/processed_sticker_dataset.parquet')\n",
    "\n",
    "# Convert embeddings to float32 numpy array\n",
    "df[\"combined_embedding\"] = df[\"combined_embedding\"].apply(lambda x: np.array(x, dtype=np.float32))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7a7ceb",
   "metadata": {},
   "source": [
    "class StickerDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.dataframe.iloc[idx]['combined_embedding']).float()\n",
    "        image_tensor = torch.load(self.dataframe.iloc[idx]['image_path']).float()\n",
    "        return embedding, image_tensor\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc9088d",
   "metadata": {},
   "source": [
    "dataset = StickerDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce6fdfc9c7643c79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:06:50.376888Z",
     "start_time": "2025-02-13T14:06:50.368062Z"
    }
   },
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, embedding_dim, image_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + embedding_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, image_channels * 32 * 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, embed):\n",
    "        x = torch.cat((noise, embed), dim=1)\n",
    "        x = self.model(x)\n",
    "        return x.view(x.size(0), 3, 32, 32)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "137e74a8",
   "metadata": {},
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, embedding_dim, image_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_channels * 32 * 32 + embedding_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, embed):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        x = torch.cat((img_flat, embed), dim=1)\n",
    "        return self.model(x)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eb8e49c8ff3a408",
   "metadata": {},
   "source": [
    "noise_dim = 100\n",
    "embedding_dim = len(df['combined_embedding'][0])\n",
    "generator = Generator(noise_dim, embedding_dim).to(device)\n",
    "discriminator = Discriminator(embedding_dim).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "    \n",
    "    for embeddings, real_images in progress_bar:\n",
    "        embeddings, real_images = embeddings.to(device), real_images.to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        noise = torch.randn(real_images.size(0), noise_dim).to(device)\n",
    "        fake_images = generator(noise, embeddings)\n",
    "        \n",
    "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n",
    "        \n",
    "        real_outputs = discriminator(real_images, embeddings)\n",
    "        fake_outputs = discriminator(fake_images.detach(), embeddings)\n",
    "        \n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        fake_outputs = discriminator(fake_images, embeddings)\n",
    "        g_loss = criterion(fake_outputs, real_labels)\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    tqdm.write(f\"Epoch [{epoch+1}/{num_epochs}] | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4956ca",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "def generate_stickers(descriptions, generator):\n",
    "    generator.eval()\n",
    "    stickers = []\n",
    "    for description in descriptions:\n",
    "        embedding = sbert_model.encode(description)\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        noise = torch.randn(1, noise_dim).to(device)\n",
    "        with torch.no_grad():\n",
    "            fake_image = generator(noise, embedding).squeeze(0).cpu().numpy()\n",
    "        stickers.append(fake_image)\n",
    "    return stickers\n",
    "\n",
    "def display_stickers(images):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(len(images) * 3, 3))\n",
    "    for ax, image in zip(axes, images):\n",
    "        image = (image + 1) / 2  # Normalize to [0,1]\n",
    "        ax.imshow(np.transpose(image, (1, 2, 0)))\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: Generate & Display Multiple Stickers\n",
    "descriptions = [\"A happy sun wearing sunglasses\", \"A cute panda waving\", \"A colorful unicorn smiling\"]\n",
    "stickers = generate_stickers(descriptions, generator)\n",
    "display_stickers(stickers)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
