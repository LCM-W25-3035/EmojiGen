{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Load Parquet file into a DataFrame\n",
    "df = pd.read_parquet(\"../data/processed_sticker_dataset.parquet\")\n",
    "\n",
    "# df[\"combined_embedding\"] = df[\"combined_embedding\"].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "\n",
    "# # Assuming 'image' column contains base64 or binary data:\n",
    "# # If it's base64-encoded\n",
    "# # def decode_image_base64(base64_string):\n",
    "# #     from io import BytesIO\n",
    "# #     from base64 import b64decode\n",
    "# #     image_data = b64decode(base64_string)\n",
    "# #     image = Image.open(BytesIO(image_data))\n",
    "# #     return image\n",
    "\n",
    "# # Or if images are stored as binary blobs\n",
    "# def decode_image_binary(binary_data):\n",
    "#     image = Image.open(io.BytesIO(binary_data))\n",
    "#     return image\n",
    "\n",
    "# # # For base64 example\n",
    "# # df['decoded_images'] = df['image_path'].apply(decode_image_base64)\n",
    "# # For binary blobs\n",
    "# df['decoded_images'] = df['combined_embedding'].apply(decode_image_binary)\n",
    "\n",
    "# # Show the first image from your dataset\n",
    "# df['decoded_images'][0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  combined_embedding  \\\n",
      "0  [0.05615041, 0.06784809, -0.03342954, 0.037553...   \n",
      "1  [-0.124234326, 0.07463956, -0.011985385, 0.004...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [-0.06495428, -0.04292713, 0.013164402, 0.0220...   \n",
      "4  [0.027918205, 0.075559475, 0.03622711, -0.0181...   \n",
      "\n",
      "                                          image_path  \n",
      "0  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
      "1  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
      "2  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
      "3  ../data/tensor_images/AlexatorStickers\\cartoon...  \n",
      "4  ../data/tensor_images/AlexatorStickers\\cartoon...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusers import StableDiffusionPipeline\n",
    "# import torch\n",
    "# from PIL import Image\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Load the Stable Diffusion model (make sure you have a Hugging Face API key if needed)\n",
    "# model = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v-1-4-original\")\n",
    "# model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Example: Process each row in the DataFrame\n",
    "# for index, row in df.iterrows():\n",
    "#     # Extract embedding and image path (you can skip embedding if you're using the path directly)\n",
    "#     image_path = row['image_path']\n",
    "    \n",
    "#     # If you want to generate from the embedding, use it as the input (e.g., for text-to-image generation)\n",
    "#     # Alternatively, you can generate based on image path if you have it\n",
    "\n",
    "#     # Load image (if you have a direct path to the image file)\n",
    "#     if image_path.startswith(\"http\"):\n",
    "#         response = requests.get(image_path)\n",
    "#         img = Image.open(BytesIO(response.content))\n",
    "#     else:\n",
    "#         img = Image.open(image_path)\n",
    "\n",
    "#     # Generate a sticker from the image using LDM or an additional text prompt\n",
    "#     prompt = \"A cute sticker with the image\"\n",
    "#     generated_img = model(prompt).images[0]\n",
    "\n",
    "#     # Save or display the generated sticker\n",
    "#     generated_img.save(f\"sticker_{index}.png\")\n",
    "#     generated_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ad30e68b9f4fbc8cd7c6b09282f0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch C:\\Users\\97798\\.cache\\huggingface\\hub\\models--CompVis--ldm-text2im-large-256\\snapshots\\30de525ca11a880baea4962827fb6cb0bb268955\\unet: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\97798\\.cache\\huggingface\\hub\\models--CompVis--ldm-text2im-large-256\\snapshots\\30de525ca11a880baea4962827fb6cb0bb268955\\unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch C:\\Users\\97798\\.cache\\huggingface\\hub\\models--CompVis--ldm-text2im-large-256\\snapshots\\30de525ca11a880baea4962827fb6cb0bb268955\\vqvae: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\97798\\.cache\\huggingface\\hub\\models--CompVis--ldm-text2im-large-256\\snapshots\\30de525ca11a880baea4962827fb6cb0bb268955\\vqvae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "The config attributes {'timestep_values': None} were passed to DDIMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9af74e2ab01462bbd136b2593cafddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Load the smallest LDM model\n",
    "pipe = DiffusionPipeline.from_pretrained(\"CompVis/ldm-text2im-large-256\", torch_dtype=torch.float32)\n",
    "\n",
    "# Move model to CPU\n",
    "pipe.to(\"cpu\")\n",
    "\n",
    "print(\"Model running on:\", pipe.device)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the image path from the Parquet file (local file path)\n",
    "    image_path = row['image_path']\n",
    "\n",
    "    # 4. Check if the image path is a tensor file (.pt)\n",
    "    if image_path.endswith(\".pt\"):\n",
    "        try:\n",
    "            # Load the tensor from the .pt file\n",
    "            tensor_image = torch.load(image_path)\n",
    "\n",
    "            # Ensure the tensor is in the correct shape (e.g., C x H x W)\n",
    "            if tensor_image.ndimension() == 3:  # Check if it's a 3D tensor (C, H, W)\n",
    "                # Convert the tensor to a PIL image (assuming the tensor is in the range [0, 1])\n",
    "                tensor_image = tensor_image.permute(1, 2, 0)  # Convert from C x H x W to H x W x C\n",
    "                tensor_image = tensor_image.numpy()  # Convert to numpy array\n",
    "                pil_image = Image.fromarray((tensor_image * 255).astype('uint8'))  # Convert to uint8 for PIL\n",
    "            else:\n",
    "                print(f\"Warning: Tensor shape of image '{image_path}' is not valid. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading tensor image from {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        # If the image path is not a tensor file, assume it's a normal image file\n",
    "        if os.path.exists(image_path):\n",
    "            pil_image = Image.open(image_path)\n",
    "        else:\n",
    "            print(f\"Warning: Image path '{image_path}' does not exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "prompt = \"unicorn wearing suit\"\n",
    "image = pipe(prompt, guidance_scale=7.5).images[0]\n",
    "\n",
    "# Save & Show Image\n",
    "image.save(\"cpu_generated_sticker.png\")\n",
    "image.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
